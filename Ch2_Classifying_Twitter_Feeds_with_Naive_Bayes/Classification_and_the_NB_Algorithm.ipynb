{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52bd2194-4d6b-4baa-b35b-ca0961aa2ec2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Classification and the Naive Bayes Algorithm\n",
    "## Mastering Machine Learning on AWS\n",
    "### Section 2, Chapter 2\n",
    "\n",
    "In this notebook we will use data from Kaggle for classification.  These are pre-labelled text documents, found [here](https://www.kaggle.com/datasets/dipankarsrirag/topic-modelling-on-emails).  There are four categories, `Crime` (1100), `Entertainment` (1053), `Politics` (3001), `Science` (4000).  We will start by choosing `Politics` and `Science` to train a binary classifier.  The model will use 2500 cases to train, 250 to validate, and 250 to test.  Our evaluation metric will be model accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ded267-840a-49f5-8485-e915ad4f2d06",
   "metadata": {},
   "source": [
    "# Contents \n",
    "\n",
    "1. [Modules and Libraries](#Modules-and-Libraries)  \n",
    "2. [Download Data](#Download-Data)  \n",
    "3. [Define data variables and Import Data](#Define-data-variables-and-Import-Data)  \n",
    "    1. [Importing Data with `read_text_files`](#Importing-Data-with-read_text_files)\n",
    "    2. ~[Split Data, creating text files for later analysis](#Split-Data,-creating-text-files-for-later-analysis)~  \n",
    "4. [Data Exploration](#Data-Exploration)\n",
    "    1. [Crime Data](#Crime-Data)\n",
    "    2. [Entertainment Data](#Entertainment-Data)\n",
    "    3. [Science Data](#Science-Data)\n",
    "    4. [Politics-Data](#Politics-Data)\n",
    "5. [Duplicate Data Check](#Duplicate-Data-Check)\n",
    "    1. [Crime vs Entertainment](#Crime-vs-Entertainment)\n",
    "    2. [Science vs Politics](#Science-vs-Politics)\n",
    "    3. [Science vs Crime](#Science-vs-Crime)\n",
    "    4. [Politics vs Crime](#Politics-vs-Crime)  \n",
    "6. [Naive Bayes Classifier](#Naive-Bayes-Classifier)\n",
    "    1. [Split the data: Training, Validation, and Testing sets](#Split-the-data:-Training,-Validation,-and-Testing-sets)\n",
    "    2. [Politics vs Science](#Politics-vs-Science)\n",
    "    3. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1735ae-ed05-4ee7-9d54-aa9824a7762f",
   "metadata": {},
   "source": [
    "## Modules and Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe87fc6f-dc5b-4bcb-aa24-8682a3a8849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import praw   # Python Reddit API Wrapper\n",
    "import datetime as dt\n",
    "import time\n",
    "import requests\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# nltk.download('stopwords') \n",
    "# nltk.download('punkt_tab')\n",
    "# nltk.download(\"wordnet\")\n",
    "# nltk.download(\"omw-1.4\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'\n",
    "\n",
    "import bnaivebayes as bnb\n",
    "import readtextfunctions as rtf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb075a61-2651-4639-8f61-a401e3a76a9a",
   "metadata": {},
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc03d07b-87de-4802-94b7-a4e3717858f3",
   "metadata": {},
   "source": [
    "This is the script that was used to download and show where the data is located.\n",
    "```python\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"dipankarsrirag/topic-modelling-on-emails\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "```\n",
    "Output: `Path to dataset files: /Users/blakewallace/.cache/kagglehub/datasets/dipankarsrirag/topic-modelling-on-emails/versions/1`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df28d72a-7de3-4a6f-ad04-b03de3243840",
   "metadata": {},
   "source": [
    "## Define data variables and Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01ea843e-9270-43d9-9f6e-6b4b20b3ae8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def read_text_files(folder_path):\n",
    "    \"\"\"\n",
    "    Reads all text files in a specified folder and returns their content.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): The path to the folder containing the text files.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are file names and values are file contents.\n",
    "               Returns an empty dictionary if the folder does not exist or \n",
    "               no text files are found.\n",
    "    \"\"\"\n",
    "    file_contents = {}\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Error: Folder '{folder_path}' not found.\")\n",
    "        return file_contents\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                with open(file_path, 'r') as file:\n",
    "                    file_contents[filename] = file.read()\n",
    "            except Exception as e:\n",
    "                 print(f\"Error reading {filename}: {e}\")\n",
    "    return file_contents\n",
    "\n",
    "# Example Usage\n",
    "\n",
    "# if text_files_data:\n",
    "    # for filename, content in text_files_data.items():\n",
    "        # print(f\"Contents of {filename}:\\n{content}\\n---\")\n",
    "# else:\n",
    "    # print(\"No text files found or an error occurred.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b8d9fb-d4a1-46cf-b06b-b1380d49e0ba",
   "metadata": {},
   "source": [
    "### Importing Data with `read_text_files`\n",
    "\n",
    "This data is in the location on the system that it was downloaded to in the [Download Data](#Download-Data) section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36bc5e02-509a-47ae-aa38-eee8e18a13a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/blakewallace/.cache/kagglehub/datasets/dipankarsrirag/topic-modelling-on-emails/versions/1/Data/Crime/\n",
      "Error reading 15672.txt: 'utf-8' codec can't decode byte 0xa0 in position 896: invalid start byte\n",
      "\n",
      "/Users/blakewallace/.cache/kagglehub/datasets/dipankarsrirag/topic-modelling-on-emails/versions/1/Data/Entertainment/\n",
      "Error reading 15672.txt: 'utf-8' codec can't decode byte 0xa0 in position 896: invalid start byte\n",
      "\n",
      "/Users/blakewallace/.cache/kagglehub/datasets/dipankarsrirag/topic-modelling-on-emails/versions/1/Data/Politics/\n",
      "\n",
      "/Users/blakewallace/.cache/kagglehub/datasets/dipankarsrirag/topic-modelling-on-emails/versions/1/Data/Science/\n",
      "Error reading 15672.txt: 'utf-8' codec can't decode byte 0xa0 in position 896: invalid start byte\n",
      "Error reading 53721.txt: 'utf-8' codec can't decode byte 0xfd in position 195: invalid start byte\n",
      "Error reading 53803.txt: 'utf-8' codec can't decode byte 0xfd in position 285: invalid start byte\n",
      "Error reading 53883.txt: 'utf-8' codec can't decode byte 0xfd in position 390: invalid start byte\n",
      "Error reading 54070.txt: 'utf-8' codec can't decode byte 0xfe in position 176: invalid start byte\n",
      "Error reading 54071.txt: 'utf-8' codec can't decode byte 0xfe in position 209: invalid start byte\n",
      "Error reading 54485.txt: 'utf-8' codec can't decode byte 0xf6 in position 1532: invalid start byte\n",
      "Error reading 59055.txt: 'utf-8' codec can't decode byte 0xff in position 728: invalid start byte\n",
      "Error reading 59239.txt: 'utf-8' codec can't decode byte 0xed in position 540: invalid continuation byte\n",
      "Error reading 59535.txt: 'utf-8' codec can't decode byte 0xab in position 182: invalid start byte\n",
      "Error reading 61293.txt: 'utf-8' codec can't decode byte 0xa5 in position 931: invalid start byte\n",
      "Error reading 61534.txt: 'utf-8' codec can't decode byte 0xf8 in position 1650: invalid start byte\n",
      "Error reading 61556.txt: 'utf-8' codec can't decode byte 0xa5 in position 453: invalid start byte\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# utilize the `read_text_files` function in the readtextfunctions file\n",
    "for directory in ['Crime', 'Entertainment', 'Politics', 'Science']:\n",
    "    folder_path = \"/Users/blakewallace/.cache/kagglehub/datasets/dipankarsrirag/topic-modelling-on-emails/versions/1/Data/\" + directory + \"/\"  # Replace with the actual path to your folder\n",
    "    print(folder_path)\n",
    "    globals()['text_files_data_{}'.format(directory)] = rtf.read_text_files(folder_path)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c272f2cd-11a0-412e-bda1-6260407059ae",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93fac31-fdf2-438d-aef8-9af7500940ce",
   "metadata": {},
   "source": [
    "### Crime Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32972ad7-8c65-4d87-86af-ff81e74d7235",
   "metadata": {},
   "source": [
    "**There are 1099 files in the Crime file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f677a30b-cd5d-41fd-b196-e71911d04631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1099"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_files_data_Crime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a3bb18-0b09-4c9a-815f-e9a4c06704b5",
   "metadata": {},
   "source": [
    "**We need the data to be in lists for some of the functions that will process the data.**\n",
    "\n",
    "Create a list and a numpy array housing the Crime data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d642d0f4-607c-45c4-8686-48a0f9c61253",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Crime_list = list()\n",
    "for key in text_files_data_Crime:\n",
    "    Crime_list.append(text_files_data_Crime[key])\n",
    "\n",
    "Crime_array = np.array(Crime_list)\n",
    "# Crime_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e35d5d6c-3806-4dca-899f-b8f18253bf5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1099"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Crime_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a672196f-2167-4a04-9bd5-7836893d7048",
   "metadata": {},
   "source": [
    "### Entertainment Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588ec765-63c2-4a1c-9798-38349b373524",
   "metadata": {},
   "source": [
    "**There are 1052 files in the Entertainment file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17ab874a-a043-4e19-ac16-6671a85806de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1052"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_files_data_Entertainment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f853e0b3-5fe7-430f-a545-b01f946d7b0b",
   "metadata": {},
   "source": [
    "Create a list and a numpy array housing the Entertainment data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f1619684-33cb-4611-8c9c-696b048dd29f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Entertainment_list = list()\n",
    "for key in text_files_data_Entertainment:\n",
    "    Entertainment_list.append(text_files_data_Entertainment[key])\n",
    "\n",
    "Entertainment_array = np.array(Entertainment_list)\n",
    "# Entertainment_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7b728f5-18e2-492c-9a4b-a029c50efc80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1052"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Entertainment_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf62334-d593-44b5-a774-731008aed33c",
   "metadata": {},
   "source": [
    "### Science Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4417ba30-c216-4d10-815c-ae16bc339da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3987"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_files_data_Science)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9deb69c7-21be-4693-953e-8dc249971ca0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Science_list = list()\n",
    "for key in text_files_data_Science:\n",
    "    Science_list.append(text_files_data_Science[key])\n",
    "# text_files_data_Crime[list(text_files_data_Crime.keys())[0]]\n",
    "\n",
    "Science_array = np.array(Science_list)\n",
    "# Science_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "681ff40e-b2c1-43ca-9e70-75ef4c3a8249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3987"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Science_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dccb41f-f4db-49a3-8af8-eb3ff9268310",
   "metadata": {},
   "source": [
    "### Politics Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29bf5305-5763-4879-ae2e-155090b0bf9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3001"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_files_data_Politics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59dd086e-780c-4455-ab6a-f3f3590a4232",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Politics_list = list()\n",
    "for key in text_files_data_Politics:\n",
    "    Politics_list.append(text_files_data_Politics[key])\n",
    "# text_files_data_Crime[list(text_files_data_Crime.keys())[0]]\n",
    "\n",
    "Politics_array = np.array(Politics_list)\n",
    "# Politics_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "456a92da-0c96-44e8-8eca-840d395cdeec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3001"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Politics_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79918ffa-7102-4ecb-865f-8e84c43d6b3c",
   "metadata": {},
   "source": [
    "## Duplicate Data Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0583815d-6eb6-4c9d-8600-0d919337a537",
   "metadata": {},
   "source": [
    "### Crime vs Entertainment\n",
    "\n",
    "**Entertainment and Crime data are corrupt.  We will not use them in our final analysis.**\n",
    "\n",
    "We can see from the following analysis that every document in the `Entertainment` folder is also in the `Crime` folder.  We will not spend time deciding which data is corrupt.  As will be shown shortly, neither data will be used for the final model training phase.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4b1325-6653-4c6d-ab53-6783bee380b6",
   "metadata": {},
   "source": [
    "**First, attempt to train a model using the two sets of data.  This yields an accuracy of zero.**\n",
    "\n",
    "Note on functions, we are using our own custome created functions.  See the accompanying file for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77307fa-adeb-454c-b5b4-4a9526762c51",
   "metadata": {},
   "source": [
    "The Naive Bayes model here removes stopwords and uses NLTK's built in word lemmatizer (nltk.stem.WordNetLemmatizer()).  However, at this point in the analysis there is no consideration of any Parts of Speech, and no POS partitioning to determine any type of term importance is being considered.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c1329bfd-467c-4cab-b43e-8b0347b1b269",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train a `Naive Bayes` model on 1000 elements from each dataset\n",
    "crimeVSentertainment_weights = bnb.trainNaiveBayes(Crime_array[:1000], Entertainment_array[:1000]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a968955-c69f-45eb-bd7f-ec710b2a4998",
   "metadata": {},
   "source": [
    "There are **14883** terms in this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8330f117-6372-47bd-adcb-429563473bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14883"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(crimeVSentertainment_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b05ecea-1a32-4d65-a18d-2e47f528c156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training accuracy\n",
    "bnb.PredAccuracy(Crime_array[:1000], Entertainment_array[:1000], crimeVSentertainment_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fb201f-6f75-4523-bc61-939fe7142ebf",
   "metadata": {},
   "source": [
    "**Looking at an example element in the `Crime` data reveals that the two datasets might have the same data.**\n",
    "\n",
    "The Score function is used to determine which class label to assign to each instance.  The left entry in the output list is associated with the label `Crime`, while the right is associated with the label `Entertainment`.  The higher of the two (which is always non-positive) is the label assigned to the instance.  In this example, the model is not able to assign a class label to the instance because the scores are identical.  This is because when generating the model weights during training the number of each feature associated with each label is identical, so the feature probabilities are identical.  \n",
    "\n",
    "The data is likely identical in both data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a487f9f-c4e6-4768-aed7-bbdb11c56959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-268.8481402335173, -268.8481402335173]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similar score for each of the class labels\n",
    "bnb.Score(Crime_array[4], crimeVSentertainment_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99323dc6-43df-4f83-a98b-7f065169d175",
   "metadata": {},
   "source": [
    "**Notice, all of the scores look to be identical in the weights generated by the Naive Bayes model.  This hints towards duplicate data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e1842bb-495b-4238-af30-4579e998cf00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "archivename: [-9.230412570777837, -9.230412570777837]\n",
      "ripemfaq: [-10.904389004349508, -10.904389004349508]\n",
      "lastupdate: [-10.904389004349508, -10.904389004349508]\n",
      "sun: [-8.28942922631331, -8.28942922631331]\n",
      "mar: [-10.616706931897728, -10.616706931897728]\n",
      "post: [-6.203908638557092, -6.203908638557092]\n",
      "still: [-6.826851560443789, -6.826851560443789]\n",
      "rather: [-6.891013504661075, -6.891013504661075]\n",
      "rough: [-9.805776715681398, -9.805776715681398]\n",
      "list: [-6.879037313614359, -6.879037313614359]\n",
      "likely: [-7.275613474305277, -7.275613474305277]\n",
      "question: [-6.543415778873459, -6.543415778873459]\n",
      "information: [-5.794411266920989, -5.794411266920989]\n",
      "ripem: [-7.040156662757711, -7.040156662757711]\n",
      "program: [-6.336574604905185, -6.336574604905185]\n",
      "public: [-5.871774803534477, -5.871774803534477]\n",
      "key: [-4.474669526310371, -4.474669526310371]\n",
      "mail: [-6.556263921351308, -6.556263921351308]\n",
      "encryption: [-5.152875126872117, -5.152875126872117]\n",
      "faq: [-7.368272304787982, -7.368272304787982]\n"
     ]
    }
   ],
   "source": [
    "# first 20 elemnts in the weights dictionary\n",
    "bnb.print_first_n_items(crimeVSentertainment_weights, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7b4512-805c-4b6b-9036-a91109764973",
   "metadata": {},
   "source": [
    "**We can confirm that all of the weights are identical.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d001f4-cc83-4bed-b007-d5632e6efc8b",
   "metadata": {},
   "source": [
    "**Number of features in the Naive Bayes model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "419b9a58-1a1f-4a8a-8a1f-1775d6d16b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14883"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(crimeVSentertainment_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a81c2b-7893-4689-982d-480b67a6ae4d",
   "metadata": {},
   "source": [
    "**Generate a comparison count between the label scores in the set of weights.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a826da57-c512-4366-8a73-1f1415fad76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number different:\u001b[1m 0\u001b[0m\n",
      "Number checked:\u001b[1m 14883\u001b[0m\n",
      "Number identical:\u001b[1m 14883\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "number_different = 0                                       # count the number that are different\n",
    "number_checked = 0                                         # count the number that are checked\n",
    "for key, value in crimeVSentertainment_weights.items():\n",
    "    if value[0] == value[1]:                               # compare each entry\n",
    "        number_checked += 1\n",
    "    else:\n",
    "        number_different += 1\n",
    "        number_checked += 1\n",
    "\n",
    "print('Number different:' + color.BOLD + f' {number_different}' + color.END)\n",
    "print('Number checked:' + color.BOLD + f' {number_checked}' + color.END)\n",
    "print('Number identical:' + color.BOLD + f' {number_checked - number_different}' + color.END)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b992f71c-ee83-4b4a-b612-c5eff8b8addd",
   "metadata": {},
   "source": [
    "**The intersection of `Crime` and `Entertainment` has 1052 elements, which is the exact number of elements in the `Entertainment` file.  Thus, everything in the `Entertainment` file is in the `Crime` file.  Duplicate data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b20a98f5-b6b8-4958-9ab2-4de949b83f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1052"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intersection, Crime vs Entertainment\n",
    "len(set(text_files_data_Crime.keys()).intersection(set(text_files_data_Entertainment.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3ec4a9-3e22-4da9-8c5a-cbb47a5d14fb",
   "metadata": {},
   "source": [
    "**47 elements are present in the `Crime` file and not the `Entertainment` file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2bbfe127-a3ad-4f6c-876d-3dad6da0b037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the number of elements in the Crime file that are not in the Entertainment file\n",
    "len(set(text_files_data_Crime.keys()) - set(text_files_data_Entertainment.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61af6db-7586-4da5-ac11-826465775330",
   "metadata": {},
   "source": [
    "**Here are the 47 document keys present in the Crime file that are not present in the Entertainment file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2d118a3-8529-4158-b949-fbd334877c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['52808.txt', '52778.txt', '52773.txt', '52769.txt', '52775.txt', '52798.txt', '52811.txt', '52784.txt', '52777.txt', '52789.txt', '52782.txt', '52787.txt', '52767.txt', '52796.txt', '52794.txt', '52779.txt', '52803.txt', '52809.txt', '52812.txt', '52770.txt', '52776.txt', '52791.txt', '52795.txt', '52772.txt', '52804.txt', '52810.txt', '52788.txt', '52783.txt', '52805.txt', '52806.txt', '52771.txt', '52790.txt', '52793.txt', '52781.txt', '52768.txt', '52792.txt', '52797.txt', '52802.txt', '52800.txt', '52799.txt', '52780.txt', '52801.txt', '52785.txt', '52813.txt', '52786.txt', '52774.txt', '52807.txt']\n"
     ]
    }
   ],
   "source": [
    "# Crime and Not Entertainment\n",
    "print(list(set(text_files_data_Crime.keys()) - set(text_files_data_Entertainment.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52895c22-a9b5-4769-83e5-9b0dbb3eafe1",
   "metadata": {},
   "source": [
    "**We will look more closely at the other sets of docuements to make sure there are no duplicates in them.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28dd72d-595b-48c4-a4ec-4867215c8432",
   "metadata": {},
   "source": [
    "### Science vs Politics \n",
    "\n",
    "**266** elements are in both the Science and Politics sets of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd5a2b49-f873-4bba-8056-1d6400d0f25c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3987"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Science, number of elements\n",
    "len(text_files_data_Science)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7faf9270-c522-4763-ace4-724f48d77eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3001"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Politics, number of elements\n",
    "len(text_files_data_Politics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3383f5d7-9852-43d2-b56e-4b4d2c44cfb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intersection, Science vs Politics\n",
    "len(set(text_files_data_Science.keys()).intersection(set(text_files_data_Politics.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1389c51-c9e5-4779-a69b-10ae80764c50",
   "metadata": {},
   "source": [
    "**266 documents are in both Science and Politics.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c7f223ac-4dd3-4c52-a890-dfb94a55cc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of shared keys:\u001b[1m 266\u001b[0m\n",
      "\n",
      "The first five shared documents: ['54116.txt', '54117.txt', '54118.txt', '54119.txt', '54120.txt'].\n"
     ]
    }
   ],
   "source": [
    "# create a list of shared keys\n",
    "shared_keys_SvsP = list()\n",
    "for key in text_files_data_Science.keys():\n",
    "    if key in text_files_data_Politics:\n",
    "        shared_keys_SvsP.append(key)\n",
    "\n",
    "# number of shared keys\n",
    "print('Number of shared keys:' + color.BOLD + f' {len(shared_keys_SvsP)}' + color.END + '\\n')\n",
    "\n",
    "# the first five document keys\n",
    "print(f'The first five shared documents: {shared_keys_SvsP[:5]}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a727429-1659-458f-8e4f-96690c7d4a3e",
   "metadata": {},
   "source": [
    "### Science vs Crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "18758cea-ef02-4855-b64a-97d85f06d598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3987"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Science, number of elements\n",
    "len(text_files_data_Science)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "11ac44e9-1941-4511-b0b4-380e4666c47c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1099"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intersection, Science vs Crime\n",
    "len(set(text_files_data_Science.keys()).intersection(set(text_files_data_Crime.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b1dfeb5d-9594-4584-a8e2-92e42a15497f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1099"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crime, number of elements\n",
    "len(text_files_data_Crime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b8a3ad-74c3-4196-85d1-9b6dbb5f7d41",
   "metadata": {},
   "source": [
    "**Every element in the Crime dataset is in the Science dataset.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64014676-e324-4bb1-91a4-70d52fd65291",
   "metadata": {},
   "source": [
    "### Politics vs Crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0b5dee21-91a7-436d-b542-0eb37a6a9183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intersection, Politics vs Crime\n",
    "len(set(text_files_data_Politics.keys()).intersection(set(text_files_data_Crime.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cb0fae-ffe2-43ea-a5ab-30e7a561213f",
   "metadata": {},
   "source": [
    "**There is no overlap between the `Politics` and `Crime` datasets.  A classifier could be trained between them.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3201333-9c10-490a-b838-6794a666c6cc",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier\n",
    "\n",
    "It has been found that everything in Entertainment is in Crime, and everything in Crime is in Science.  Thus, any attempt to train a classifier between Science and Crime or Entertainment will not work. \n",
    "\n",
    "There is no overlap between the Politics and Crime datasets, and here is slight overlap between the Politics and Science sets.  We could look at two models, one for classifying between Politics and Crime, the other to classify between Politics and Science.  But, the Crime set is a subset of the Science set.  So, creating a model between Politics and Crime is the same as creating a model between Politics and a subset of Science.  We will not do this.  Instead, we will focus exclusively on building a model between Politics and Science."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb50cd56-47a0-42e1-ba4b-7a2094adeb40",
   "metadata": {},
   "source": [
    "## Politics vs Science \n",
    "\n",
    "Recall, there were **266** shared elements between these two datasets.  We will begin by removing these duplicates from each dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "965557e7-018b-4563-90a9-ba48bc8d71d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shared_keys_SvsP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0cd39395-4b50-41ae-875b-3926fde09cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3001"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_files_data_Politics.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "125ac40c-9b66-4b7c-9623-d1109fb81d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2735"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the shared keys from Politics\n",
    "for key in shared_keys_SvsP:\n",
    "    if key in text_files_data_Politics:\n",
    "        del text_files_data_Politics[key]\n",
    "\n",
    "len(text_files_data_Politics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d365285-2ff5-45d2-9b0a-851ebf1272d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3721"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the shared keys from Science\n",
    "for key in shared_keys_SvsP:\n",
    "    if key in text_files_data_Science:\n",
    "        del text_files_data_Science[key]\n",
    "\n",
    "len(text_files_data_Science)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6708f6-80f8-4be4-9b76-18a6507c7882",
   "metadata": {},
   "source": [
    "### Split the data: Training, Validation, and Testing sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4948a019-74ff-4ed0-9555-e5cb5a10bfc2",
   "metadata": {},
   "source": [
    "#### New lists and arrays of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3e916327-b363-40a2-9c91-19e45f920613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poilitcs set size:\u001b[1m 2735\u001b[0m\n",
      "Science set size:\u001b[1m 3721\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print('Poilitcs set size:' + color.BOLD + f' {len(text_files_data_Politics)}' + color.END)\n",
    "print('Science set size:' + color.BOLD + f' {len(text_files_data_Science)}' + color.END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3d50f9bc-1bd3-416d-b3c2-dbd8440fb423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Politics\n",
    "Politics_list = list()\n",
    "for key in text_files_data_Politics:\n",
    "    Politics_list.append(text_files_data_Politics[key])\n",
    "\n",
    "Politics_array = np.array(Politics_list)\n",
    "\n",
    "# Science\n",
    "Science_list = list()\n",
    "for key in text_files_data_Science:\n",
    "    Science_list.append(text_files_data_Science[key])\n",
    "\n",
    "Science_array = np.array(Science_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b5479c0e-bbcb-4831-9272-8e8441e2fe2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poilitcs set size:\u001b[1m 2735\u001b[0m\n",
      "Science set size:\u001b[1m 3721\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print('Poilitcs set size:' + color.BOLD + f' {len(Politics_array)}' + color.END)\n",
    "print('Science set size:' + color.BOLD + f' {len(Science_array)}' + color.END)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa53bc0-0601-4090-9ebf-a9afea740d3f",
   "metadata": {},
   "source": [
    "#### Train, Validation, Test Split\n",
    "\n",
    "**<u>Instances from each set</u>:**  \n",
    "Training: 2435 instances  \n",
    "Validation: 150 instances  \n",
    "Testing: 150 instances  \n",
    "\n",
    "These numbers use all of the instances in the Politics set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e49fd1-ba95-4966-a44d-9163a906b6dd",
   "metadata": {},
   "source": [
    "**Politics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "11e7ff46-b709-4fbd-8470-e9608518c67b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "# np.random.shuffle(Politics_array)\n",
    "\n",
    "Politics_copy = np.empty_like(Politics_array)\n",
    "np.copyto(Politics_copy, Politics_array)\n",
    "\n",
    "np.random.shuffle(Politics_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1fdc3d25-f4a5-4fe4-bcba-4d9649408696",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_p = list(Politics_copy[:2435])\n",
    "val_p = list(Politics_copy[2435:2585])\n",
    "test_p = list(Politics_copy[2585:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "198b5d92-7489-46cc-90ff-f4a0df06fddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poilitcs Training size:\u001b[1m 2435\u001b[0m\n",
      "Politics Validation size:\u001b[1m 150\u001b[0m\n",
      "Politics Testing size:\u001b[1m 150\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print('Poilitcs Training size:' + color.BOLD + f' {len(train_p)}' + color.END)\n",
    "print('Politics Validation size:' + color.BOLD + f' {len(val_p)}' + color.END)\n",
    "print('Politics Testing size:' + color.BOLD + f' {len(test_p)}' + color.END)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadc1bfd-47f3-4520-bf98-4be77f1a9c23",
   "metadata": {},
   "source": [
    "**Science**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9c3ab976-588f-4711-add2-29d07c01ed91",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "# np.random.shuffle(Science_array)\n",
    "\n",
    "# np.random.seed(42)\n",
    "# np.random.shuffle(Politics_array)\n",
    "\n",
    "Science_copy = np.empty_like(Science_array)\n",
    "np.copyto(Science_copy, Science_array)\n",
    "\n",
    "np.random.shuffle(Science_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8c763dd8-f22e-4370-9613-068e48723451",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s = list(Science_copy[:2435])\n",
    "val_s = list(Science_copy[2435:2585])\n",
    "test_s = list(Science_copy[2585:2735])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "54747121-9811-4d67-9e42-36b430348132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Science Training size:\u001b[1m 2435\u001b[0m\n",
      "Science Validation size:\u001b[1m 150\u001b[0m\n",
      "Science Testing size:\u001b[1m 150\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print('Science Training size:' + color.BOLD + f' {len(train_s)}' + color.END)\n",
    "print('Science Validation size:' + color.BOLD + f' {len(val_s)}' + color.END)\n",
    "print('Science Testing size:' + color.BOLD + f' {len(test_s)}' + color.END)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d54d464-bb4a-4dc7-a2e4-6ad217c87220",
   "metadata": {},
   "source": [
    "### Politics vs Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f16ac501-6a18-476e-bb5b-4f2a4aaf7e77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "PvsS_weights = bnb.NaiveBayes(train_p, train_s)\n",
    "bnb.LogWeights(PvsS_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c1dbfab2-c2b9-4d95-81c9-c6443f426169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50617"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are 50617 features in the trained model\n",
    "len(PvsS_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "12c0c216-91c0-4ad2-81b8-087a89bb9713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9936344969199179"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Score\n",
    "train_score = bnb.PredAccuracy(train_p, train_s, PvsS_weights)\n",
    "train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "5f2f5364-5d46-4daf-8354-00367a2fd368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9733333333333334"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation Score (0.98)\n",
    "val_score = bnb.PredAccuracy(val_p, val_s, PvsS_weights)\n",
    "val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6c4e6816-16ae-4360-b634-725fe1ee1265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.020301163586584514\n",
      "2.03%\n"
     ]
    }
   ],
   "source": [
    "# Training - Validation\n",
    "print(train_score - val_score)\n",
    "print(str(round(train_score - val_score, 5)*100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "95471bd1-ea35-48fa-8008-18e63f9b5053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9833333333333333"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing Score\n",
    "bnb.PredAccuracy(test_p, test_s, PvsS_weights)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0110dee3-fc2a-4cc2-bcc0-ebf68a06b32e",
   "metadata": {},
   "source": [
    "## Missclassified Training cases explored"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f85b9c-639c-48b7-a75f-a7a9fa2ef7a7",
   "metadata": {},
   "source": [
    "### Number Missclassified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "6d6fd65d-80a5-4e1b-84ca-2827005999bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:\u001b[1m 0.9936344969199179\u001b[0m\n",
      "Training set size:\u001b[1m 4870\u001b[0m\n",
      "Total Missclassified\u001b[1m 31\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print('Training score:' + color.BOLD + f' {train_score}' + color.END)\n",
    "print('Training set size:' + color.BOLD + f' {len(train_p) + len(train_s)}' + color.END)\n",
    "print('Total Missclassified' + color.BOLD + f' {round((1 - train_score) * (len(train_p) + len(train_s)))}' + color.END)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327fffe0-ca17-4620-9bd1-d40235c488fe",
   "metadata": {},
   "source": [
    "### Missclassified Cases located"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec353fe-7bdb-4996-9ea4-52dfc7376e0a",
   "metadata": {},
   "source": [
    "#### Cases with empty string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "7d48fced-d7b6-4088-9b15-38e73c4b11e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Politics_list[1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2262af6-78cb-4d5c-a2de-77b86902b7a6",
   "metadata": {},
   "source": [
    "**There are 19 empty cases in the training data.**\n",
    "\n",
    "7 in Politics  \n",
    "12 in Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "705996c0-1f4e-4366-9114-b7d72a13cdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Politics, number empty:\u001b[1m 7\u001b[0m\n",
      "Science, number empty:\u001b[1m 12\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Politics set, number empty\n",
    "number_empty_p = 0\n",
    "for item in train_p:\n",
    "    if item == '':\n",
    "        number_empty_p += 1\n",
    "\n",
    "# Science set, number empty\n",
    "number_empty_s = 0\n",
    "for item in train_s:\n",
    "    if item == '':\n",
    "        number_empty_s += 1\n",
    "\n",
    "print('Politics, number empty:' + color.BOLD + f' {number_empty_p}' + color.END)\n",
    "print('Science, number empty:' + color.BOLD + f' {number_empty_s}' + color.END)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c65f825-9b48-46e7-b8f0-54f92aa85eb8",
   "metadata": {},
   "source": [
    "**These are being missclassified because the Score function is returning equil scores for each class.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4b719f6a-96a8-4c97-b7f4-c3f90221e812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.Score(Politics_list[1:2][0], PvsS_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac41d59-e022-4d0e-b498-e726793fd088",
   "metadata": {},
   "source": [
    "**These 19 empty cases account for 19 of the 30 errors in the training score.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "14c6455f-0404-4fc6-b0a8-ae214f70eae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2435"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "fc55aec9-3f0e-4860-812a-ed8344c63ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7):\n",
    "    train_p.remove('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "1a37e045-3d28-49b0-b7c0-9fd9a2c420c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2428"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "062cf634-47b2-47e5-b3cb-d44b8e9bb84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2435"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "5b54c085-507a-4f31-8f04-5d50edb41287",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(12):\n",
    "    train_s.remove('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b072eaa1-2b12-45b1-8582-e8ff93841531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2423"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c8bed7c1-6c1b-417a-9b33-e53f38ea3a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Politics, number empty:\u001b[1m 0\u001b[0m\n",
      "Science, number empty:\u001b[1m 0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Politics set, number empty\n",
    "number_empty_p = 0\n",
    "for item in train_p:\n",
    "    if item == '':\n",
    "        number_empty_p += 1\n",
    "\n",
    "# Science set, number empty\n",
    "number_empty_s = 0\n",
    "for item in train_s:\n",
    "    if item == '':\n",
    "        number_empty_s += 1\n",
    "\n",
    "print('Politics, number empty:' + color.BOLD + f' {number_empty_p}' + color.END)\n",
    "print('Science, number empty:' + color.BOLD + f' {number_empty_s}' + color.END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "c766d0f7-456c-40c4-9df8-bf8c991f4b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training accuracy, recomputed\n",
    "train_score_1 = bnb.PredAccuracy(train_p, train_s, PvsS_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "450e89d0-2c09-4f34-9d89-cdee773b2bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:\u001b[1m 0.9975262832405689\u001b[0m\n",
      "Training set size:\u001b[1m 4851\u001b[0m\n",
      "Total Missclassified\u001b[1m 12\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print('Training score:' + color.BOLD + f' {train_score_1}' + color.END)\n",
    "print('Training set size:' + color.BOLD + f' {len(train_p) + len(train_s)}' + color.END)\n",
    "print('Total Missclassified' + color.BOLD + f' {round((1 - train_score_1) * (len(train_p) + len(train_s)))}' + color.END)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89541409-0922-4a17-9100-f564e31bbb10",
   "metadata": {},
   "source": [
    "#### Non-empty missclassified cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ce08f9-138c-411e-ab31-a1e83066e68b",
   "metadata": {},
   "source": [
    "**Locate missclassified Politics cases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "3a1d9155-37fd-45df-a493-db937f658040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[141, 2107, 2277, 2323, 2391]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_missclassified = list()\n",
    "for i in range(len(train_p)):\n",
    "    if bnb.Score(train_p[i], PvsS_weights)[0] < bnb.Score(train_p[i], PvsS_weights)[1]:\n",
    "        index_missclassified.append(i)\n",
    "\n",
    "index_missclassified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "3f05cdff-8773-43dc-b8dd-0c5b4060da7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-66.76779799996136, -62.97423908335089]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.Score(train_p[141], PvsS_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "e6b98de7-ce10-4461-bce5-8f603cbcf95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   \n",
      "\n",
      "does anyone have the e-mail address for the white house. if so please send it to\n",
      "me thanks a lot.\n",
      "\n",
      "\n",
      "    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 141\n",
    "print(train_p[141])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "b4626c83-6525-45ed-8556-fbbe549bb78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thanks to everyone who sent replies regarding this case.  A few of them were\n",
      "very informative and helped very much. \n",
      "\n",
      "\n",
      "                     Once again.\n",
      " THANKS!                                                  T.C.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2107\n",
    "print(train_p[2107])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "2564653f-b173-4133-8520-08dfdb11012a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\tIf you look through this newsgroup, you should be \n",
      "\table to find Clinton's proposed \"Wiretapping\" Initiative\n",
      "\tfor our computer networks and telephone systems.\n",
      "\n",
      "\tThis 'initiative\" has been up before Congress for at least\n",
      "\tthe past 6 months, in the guise of the \"FBI Wiretapping\"\n",
      "\tbill.\n",
      "\n",
      "\tI strongly urge you to begin considering your future.\n",
      "\n",
      "\tI strongly urge you to get your application for a passport\n",
      "\tin the mail soon.\n",
      "\n",
      "\tI strongly urge you to consider moving any savings you \n",
      "\thave overseas, into protected bank accounts, while \n",
      "\tyou are still able.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2277\n",
    "print(train_p[2277])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "0f6c4fe0-ecd0-4146-a752-10155d195bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-373.5545973640566, -370.74823733323814]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('look', 1),\n",
       " ('newsgroup', 1),\n",
       " ('able', 2),\n",
       " ('find', 1),\n",
       " ('clintons', 1),\n",
       " ('propose', 1),\n",
       " ('wiretapping', 2),\n",
       " ('initiative', 2),\n",
       " ('computer', 1),\n",
       " ('network', 1),\n",
       " ('telephone', 1),\n",
       " ('systems', 1),\n",
       " ('congress', 1),\n",
       " ('least', 1),\n",
       " ('past', 1),\n",
       " ('months', 1),\n",
       " ('guise', 1),\n",
       " ('fbi', 1),\n",
       " ('bill', 1),\n",
       " ('strongly', 3),\n",
       " ('urge', 3),\n",
       " ('begin', 1),\n",
       " ('consider', 2),\n",
       " ('future', 1),\n",
       " ('get', 1),\n",
       " ('application', 1),\n",
       " ('passport', 1),\n",
       " ('mail', 1),\n",
       " ('soon', 1),\n",
       " ('move', 1),\n",
       " ('savings', 1),\n",
       " ('overseas', 1),\n",
       " ('protect', 1),\n",
       " ('bank', 1),\n",
       " ('account', 1),\n",
       " ('still', 1)]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(bnb.Score(train_p[2277], PvsS_weights))\n",
    "bnb.FeatureFunction(train_p[2277])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "a59a5ced-e4b7-46ae-839e-c756b15af3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-373.5545973640566, -370.74823733323814]\n",
      "\n",
      "look: [-6.453388447208584, -6.3206198582851485] 1\n",
      "newsgroup: [-9.068348225244781, -8.390399489053248] 1\n",
      "able: [-7.539245460901568, -7.258170589586153] 2\n",
      "find: [-6.369698798427278, -6.154063781600403] 1\n",
      "clintons: [-9.104066307846862, -9.802669336576399] 1\n",
      "propose: [-8.600539986562483, -8.055760433513695] 1\n",
      "wiretapping: [-10.713504220280962, -9.751376042188848] 2\n",
      "initiative: [-9.240198482171442, -8.896960714032781] 2\n",
      "computer: [-8.70468024581508, -6.994535676917207] 1\n",
      "network: [-8.622763123347193, -7.548611284477014] 1\n",
      "telephone: [-9.527880554623222, -8.102717416601466] 1\n",
      "systems: [-8.780666152793001, -7.0981340775816335] 1\n",
      "congress: [-7.630760569737341, -8.527600610566733] 1\n",
      "least: [-7.206037645024762, -7.03337551023347] 1\n",
      "past: [-7.838399934515586, -8.182760124275003] 1\n",
      "months: [-8.067974376160086, -7.819854630585635] 1\n",
      "guise: [-10.546450135617796, -11.360813954622948] 1\n",
      "fbi: [-6.683294220394736, -8.527600610566733] 1\n",
      "bill: [-7.095242333380979, -7.565324765450754] 1\n",
      "strongly: [-9.068348225244781, -9.250600754276359] 3\n",
      "urge: [-9.744103663092858, -11.13767040330874] 3\n",
      "begin: [-7.059310324154915, -7.635120527386296] 1\n",
      "consider: [-6.842303209373071, -7.274837642071365] 2\n",
      "future: [-8.100764198983077, -8.13198779890158] 1\n",
      "get: [-5.522063669908715, -5.311080499390991] 1\n",
      "application: [-10.626492843291333, -8.456648874594448] 1\n",
      "passport: [-10.626492843291333, -11.13767040330874] 1\n",
      "mail: [-8.52643201440876, -7.182587908420146] 1\n",
      "soon: [-8.392900621784237, -7.871910992541688] 1\n",
      "move: [-7.417667354276633, -8.046627949950423] 1\n",
      "savings: [-10.472342163464074, -11.13767040330874] 1\n",
      "overseas: [-11.031957951399496, -10.349213042944468] 1\n",
      "protect: [-7.6391288194078575, -7.40000078502537] 1\n",
      "bank: [-8.283085755777032, -7.910826408791362] 1\n",
      "account: [-7.7932794992351155, -8.416374975456508] 1\n",
      "still: [-6.654629837507169, -6.748171753796156] 1\n",
      "\n",
      "[-373.5545973640566, -370.74823733323814]\n"
     ]
    }
   ],
   "source": [
    "print(bnb.Score(train_p[2277], PvsS_weights))\n",
    "print()\n",
    "for index, count in bnb.FeatureFunction(train_p[2277]):\n",
    "    print(index+':', PvsS_weights[index], count)\n",
    "print()\n",
    "print(bnb.Score(train_p[2277], PvsS_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "d9e0982f-c1cb-4817-92c2-1155573d73e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['still', 'soon', 'get', 'past', 'least', 'find', 'able', 'look']"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there are words we could potential remove from the training features\n",
    "non_discrimitive = ['still', 'soon', 'get', 'past', 'least', 'find', 'able', 'look']\n",
    "non_discrimitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "fcdf4221-b6a3-4485-9cb8-8998d217877b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198\n",
      "196\n",
      "{'ourselves', 'how', 'again', 'did', 'didnt', 'theyre', 'i', 'few', 'weve', 'just', 'me', 'other', 'thatll', 'against', 'whom', 'wed', 'too', 'your', 'have', 'the', 'can', 'do', 'wouldnt', 'youd', 'and', 'she', 'himself', 'here', 'both', 'between', 'who', 'into', 'them', 'off', 'all', 'does', 'now', 'should', 'o', 'itself', 'will', 'is', 'by', 're', 'up', 'arent', 'or', 'further', 'doesn', 'we', 'theyve', 'they', 'you', 'hers', 'youre', 'that', 'shant', 'out', 'hed', 'this', 'themselves', 'ill', 'no', 'hasn', 'nor', 'with', 'itd', 'until', 'hes', 'through', 'at', 'such', 'down', 'yourself', 'ours', 'dont', 've', 'don', 'as', 'be', 'isnt', 'mightnt', 'any', 'wasn', 'didn', 'y', 's', 'hell', 'a', 'what', 'before', 'where', 'wasnt', 'couldn', 't', 'werent', 'was', 'these', 'wouldn', 'wont', 'of', 'so', 'll', 'shed', 'youll', 'ive', 'during', 'youve', 'more', 'over', 'needn', 'havent', 'aren', 'mightn', 'yourselves', 'if', 'same', 'their', 'why', 'theirs', 'being', 'which', 'itll', 'doing', 'each', 'neednt', 'isn', 'shell', 'than', 'hasnt', 'him', 'd', 'were', 'his', 'from', 'shouldn', 'because', 'very', 'shouldnt', 'ain', 'her', 'am', 'herself', 'above', 'once', 'under', 'below', 'are', 'had', 'in', 'for', 'about', 'myself', 'to', 'won', 'only', 'weren', 'our', 'shouldve', 'shan', 'mustnt', 'when', 'some', 'he', 'an', 'couldnt', 'has', 'on', 'ma', 'shes', 'theyd', 'theyll', 'm', 'there', 'having', 'those', 'my', 'while', 'its', 'been', 'not', 'yours', 'haven', 'id', 'then', 'most', 'well', 'own', 'but', 'hadn', 'mustn', 'hadnt', 'it', 'im', 'doesnt', 'after'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "STOP_WORDS = set(stopwords.words('english'))\n",
    "# STOP_WORDS\n",
    "\n",
    "stop_words = set()\n",
    "for word in STOP_WORDS:\n",
    "    new_word = str()                                     # create a string without punctuation\n",
    "    for char in word:                                    # look at each character in the word\n",
    "        if char.isalpha():                               # determine if the character is alphabetic\n",
    "            new_word += char                             # if it is alphabetic, add it to the new word\n",
    "    if new_word != '':\n",
    "        stop_words.add(new_word)\n",
    "\n",
    "print(len(STOP_WORDS))\n",
    "print(len(stop_words))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "2e8ec45e-1b92-4de7-8e4d-99090d6edc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for word in non_discrimitive:\n",
    "    print(word in stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f0b8c7-fe82-4157-a819-f680613dd297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8c9b6f-c350-4360-b39f-17cb9ed7e933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a53519f-a150-4571-a476-e345036e6613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4297de0-af01-4fe6-b3e6-bd6de2792ace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43e060f-4347-4e8d-9098-3f6a0d8fe410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999845c3-67d3-4645-9863-86ef172ff914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "399d07fb-fb15-47e2-9c8b-28dddf99240b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['The sun is shining.', 'The weather is sweet.',\n",
       "       'The sun is shining, the weather is sweet, and one and one is two.'],\n",
       "      dtype='<U65')"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = np.array(['The sun is shining.', \n",
    "                 'The weather is sweet.', \n",
    "                 'The sun is shining, the weather is sweet, and one and one is two.'])\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "dc6ab314-ab3c-465b-90a1-6da23f8df569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The sun is shining.',\n",
       " 'The weather is sweet.',\n",
       " 'The sun is shining, the weather is sweet, and one and one is two.']"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = list(['The sun is shining.', \n",
    "                 'The weather is sweet.', \n",
    "                 'The sun is shining, the weather is sweet, and one and one is two.'])\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "26dc5543-2ee8-4bbe-a005-29352102699a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for item in docs:\n",
    "    print(type(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "id": "8c6d206a-f4ed-45a6-b3f3-4d504ac9b821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocabulary(documents: list[str]) -> dict[str, int]:\n",
    "    '''Create the vocabulary given a list of documents.'''\n",
    "\n",
    "    # create array of unique words (put in numpy array)\n",
    "\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    from nltk.corpus import stopwords\n",
    "\n",
    "    # Create a set of stop words \n",
    "    STOP_WORDS = set(stopwords.words('english'))\n",
    "\n",
    "    stop_words = set()\n",
    "    for word in STOP_WORDS:\n",
    "        new_word = str()                                     # create a string without punctuation\n",
    "        for char in word:                                    # look at each character in the word\n",
    "            if char.isalpha():                               # determine if the character is alphabetic\n",
    "                new_word += char                             # if it is alphabetic, add it to the new word\n",
    "        if new_word != '':\n",
    "            stop_words.add(new_word)\n",
    "        \n",
    "    # instantiate important data types for storing processed data\n",
    "    # documents_array = documents\n",
    "    # documents_array = np.array(list(documents).strip().lower().split())  # list of potential words from string\n",
    "    vocab_list = list()                                                # dictionary for holding word counts\n",
    "\n",
    "    # Initialize wordnet lemmatizer\n",
    "    wnl = WordNetLemmatizer()\n",
    "    \n",
    "    # consider each word, determine if any of its characters are not alphabetic\n",
    "    for doc in documents:\n",
    "        # print(doc)\n",
    "        for word in doc.strip().lower().split():\n",
    "            # print(word)\n",
    "            new_word = str()                                     # create a string without punctuation\n",
    "            for char in word:                                    # look at each character in the word\n",
    "                if char.isalpha():                               # determine if the character is alphabetic\n",
    "                    new_word += char                             # if it is alphabetic, add it to the new word\n",
    "            if new_word != '':                                   # make sure the new string is not empty\n",
    "\n",
    "                newer_word = wnl.lemmatize(new_word, pos=\"v\")    # lemetize the word\n",
    "                if newer_word not in stop_words:                 # check that the new word is not a common word listed in the stop words\n",
    "            \n",
    "                # update the word count for the new word\n",
    "                    if newer_word not in vocab_list:             # determine if the new_word has been counted\n",
    "                        vocab_list.append(newer_word)\n",
    "                \n",
    "    # output = list()                                          # list of (word, count) tuples\n",
    "    # for word in dict_counts:\n",
    "    #     output.append((word, dict_counts[word]))\n",
    "\n",
    "\n",
    "    # order alphabetically the elements in the array\n",
    "    vocab_array = np.array(vocab_list)\n",
    "    vocab_array.sort()\n",
    "\n",
    "    # create a dictionary of the elements\n",
    "    vocab_dict = dict()\n",
    "    for index in range(len(vocab_array)):\n",
    "        vocab_dict[vocab_array[index]] = index\n",
    "    \n",
    "    return vocab_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "841527aa-51fb-4bdf-bd66-985a3299d7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.str_('one'): 0,\n",
       " np.str_('shin'): 1,\n",
       " np.str_('sun'): 2,\n",
       " np.str_('sweet'): 3,\n",
       " np.str_('two'): 4,\n",
       " np.str_('weather'): 5}"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "31c43e27-3197-43e1-a124-2973c45f5a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The sun is shining.',\n",
       " 'The weather is sweet.',\n",
       " 'The sun is shining, the weather is sweet, and one and one is two.']"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "490cf9b6-7e2c-4fb9-b3e7-c64b3841428d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_vocabulary = vocabulary(train_p+train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "8ba5eaa3-e618-4845-a874-1784cfa877c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_p_vocabulary = vocabulary(train_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "f95ed09d-11b4-471e-ad91-2a826cb1d1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30185"
      ]
     },
     "execution_count": 674,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_p_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "id": "ed063daf-9723-485f-8b90-858978f13c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s_vocabulary = vocabulary(train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "id": "2e6259d7-c095-4d7b-81dd-0c5adcfe6eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31418"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_s_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "872a2160-fff1-4ae7-b827-410c17d00705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50617"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "11f3604b-87af-4ef1-aedb-04272f557ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50617"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(PvsS_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27223cf2-353d-4e58-8e45-bab131e86504",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "id": "4ed8f12d-7e67-4dad-8924-44c5ce919dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(word: str) -> str:\n",
    "\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    from nltk.corpus import stopwords    \n",
    "    \n",
    "    new_word = str()                                     # create a string without punctuation\n",
    "    for char in word:                                    # look at each character in the word\n",
    "        if char.isalpha():                               # determine if the character is alphabetic\n",
    "            new_word += char                             # if it is alphabetic, add it to the new word\n",
    "\n",
    "    return new_word\n",
    "\n",
    "def lemmatize(word: str) -> str:\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    wnl = WordNetLemmatizer()\n",
    "    new_word = wnl.lemmatize(word, pos=\"v\")\n",
    "    return new_word\n",
    "\n",
    "def create_lemmatized_stopwords() -> str:\n",
    "    from nltk.corpus import stopwords\n",
    "\n",
    "    # Create a set of stop words \n",
    "    STOP_WORDS = set(stopwords.words('english'))\n",
    "\n",
    "    stop_words = set()\n",
    "    for word in STOP_WORDS:\n",
    "        new_word = str()                                     # create a string without punctuation\n",
    "        for char in word:                                    # look at each character in the word\n",
    "            if char.isalpha():                               # determine if the character is alphabetic\n",
    "                new_word += char                             # if it is alphabetic, add it to the new word\n",
    "        if new_word != '':\n",
    "            stop_words.add(new_word)\n",
    "\n",
    "    return stop_words\n",
    "\n",
    "    \n",
    "    # if new_word != '':                                   # make sure the new string is not empty\n",
    "\n",
    "    #     newer_word = wnl.lemmatize(new_word, pos=\"v\")    # lemetize the word\n",
    "    #     if newer_word not in stop_words:                 # check that the new word is not a common word listed in the stop words\n",
    "    #         return newer_word\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "id": "88677ed0-00eb-45bb-8edf-745e24b89f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(create_lemmatized_stopwords())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "id": "155d1755-678c-4de7-91a4-2637899c734f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shining'"
      ]
     },
     "execution_count": 712,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_punctuation('shining')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "id": "b9ef2d91-d013-4eb8-b64d-e677c589acc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['The sun is shining.', 'The weather is sweet.',\n",
       "       'The sun is shining, the weather is sweet, and one and one is two.'],\n",
       "      dtype='<U65')"
      ]
     },
     "execution_count": 713,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = np.array(['The sun is shining.', \n",
    "                 'The weather is sweet.', \n",
    "                 'The sun is shining, the weather is sweet, and one and one is two.'])\n",
    "docs[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "6dcc519d-fd98-4452-a41b-0446de4f39b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = train_p+train_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "id": "136cdf57-2299-4e7f-bf64-c8f148e65c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'sun', 'be', 'shin'], ['the', 'weather', 'be', 'sweet'], ['the', 'sun', 'be', 'shin', 'the', 'weather', 'be', 'sweet', 'and', 'one', 'and', 'one', 'be', 'two']]\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()\n",
    "new_docs = list()\n",
    "for doc in docs[:3]:\n",
    "    doc_list = doc.strip().lower().split()\n",
    "    # print(doc_list)\n",
    "# print(docs[0].strip().lower().split())\n",
    "# print()\n",
    "    # new_doc_list = [remove_punctuation(word) for word in doc_list]\n",
    "    # new_doc_list = [remove_punctuation(word) for word in doc_list]\n",
    "    # new_doc_list = [wnl.lemmatize(remove_punctuation(word), pos=\"v\") for word in doc_list]\n",
    "    new_doc_list = [lemmatize(remove_punctuation(word)) for word in doc_list]\n",
    "    # print(new_doc_list)\n",
    "    new_docs.append(new_doc_list)\n",
    "\n",
    "print(new_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "id": "6bb3da82-eb76-4c70-ad54-230290a6c700",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = create_stopwords()\n",
    "from scipy.sparse import csr_matrix\n",
    "# docs = [[\"hello\", \"world\", \"hello\"], [\"goodbye\", \"cruel\", \"world\"]]\n",
    "# docs = [['the', 'sun', 'be', 'shin'], ['the', 'sun', 'be', 'shin'],['the', 'sun', 'be', 'shin']]\n",
    "indptr = [0]\n",
    "indices = []\n",
    "data = []\n",
    "vocabulary = {}\n",
    "for d in new_docs:\n",
    "    for term in d:\n",
    "        if term in stop_words:\n",
    "            continue\n",
    "        elif term == '':\n",
    "            continue\n",
    "        else:\n",
    "            index = vocabulary.setdefault(term, len(vocabulary))\n",
    "            indices.append(index)\n",
    "            data.append(1)\n",
    "    indptr.append(len(indices))\n",
    "term_frequency_vectors = csr_matrix((data, indices, indptr), dtype=int).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "id": "07ae6f0d-9116-46a7-9a99-098d4d359076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 716,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "id": "629358dd-fbae-4538-8659-1e27ad5050e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 0, 1, 2, 3, 4, 4, 5]"
      ]
     },
     "execution_count": 717,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "id": "7164e73b-b23d-4f37-9635-8ee120cd8d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sun': 0, 'shin': 1, 'weather': 2, 'sweet': 3, 'one': 4, 'two': 5}"
      ]
     },
     "execution_count": 718,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "id": "8789b5e2-08f7-40d3-a90c-94fb4f5766b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 4, 11]"
      ]
     },
     "execution_count": 719,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "id": "cb0b7b3b-21fe-4e31-9a25-25f304618ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 1, 0, 0],\n",
       "       [1, 1, 1, 1, 2, 1]])"
      ]
     },
     "execution_count": 720,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_frequency_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "id": "cf807479-5ee0-4dc6-bbd0-559c284633be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "id": "fe9fc3e9-b98c-4e4b-a1d4-d78b1da61756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sun': 0, 'shin': 1, 'weather': 2, 'sweet': 3, 'one': 4, 'two': 5}"
      ]
     },
     "execution_count": 722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "id": "6dce0f78-89ab-479e-b5f6-d3c67b2fe49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 723,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_vocabulary = dict(sorted(vocabulary.items()))\n",
    "len(sorted_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "807d4642-9ec1-4008-b161-cd255e60476b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50617"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(PvsS_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "41f34337-2959-4388-9a24-d15561d897bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sun': 0, 'shin': 1, 'weather': 2, 'sweet': 3, 'one': 4, 'two': 5}"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "a182f8cf-5b89-4f9c-84cd-53463ae08ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 1, 0, 0],\n",
       "       [1, 1, 1, 1, 2, 1]])"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_frequency_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "id": "a2107b2c-8f45-47fd-b907-2437321946ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(termFrequencyVectors: list[list[int]], vocabulary: dict[str, int]) -> list[int]:\n",
    "    tfIdf = list()\n",
    "    num_documents = len(termFrequencyVectors)\n",
    "    df = list()\n",
    "    idf = list()\n",
    "    for term, index in vocabulary.items():\n",
    "        # print(term, index)\n",
    "        document_frequency = 0\n",
    "        for document in termFrequencyVectors:\n",
    "            # print(document[index])\n",
    "            if document[index] != 0:\n",
    "                document_frequency += 1\n",
    "        df.append(document_frequency)\n",
    "        idf.append(np.log((1+num_documents)/(1+document_frequency)))\n",
    "    for item in termFrequencyVectors:\n",
    "        # print(item)\n",
    "        tf = [np.log(1+count) for count in item]\n",
    "        # print(type(tf))\n",
    "        tf_idf = list()\n",
    "        for index in range(len(tf)):\n",
    "            tf_idf.append(tf[index]*idf[index])\n",
    "        tfIdf.append(tf_idf)\n",
    "    \n",
    "    return tfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "id": "cb261343-af38-4df0-8258-f632319121cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(0.1994060174175938), np.float64(0.1994060174175938), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)]\n",
      "\n",
      "[np.float64(0.0), np.float64(0.0), np.float64(0.1994060174175938), np.float64(0.1994060174175938), np.float64(0.0), np.float64(0.0)]\n",
      "\n",
      "[np.float64(0.1994060174175938), np.float64(0.1994060174175938), np.float64(0.1994060174175938), np.float64(0.1994060174175938), np.float64(0.761500010418809), np.float64(0.4804530139182014)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for document in tf_idf(term_frequency_vectors, vocabulary):\n",
    "    print(document)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "id": "0914a419-e8bc-427b-8615-df1d5919d75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sun': 0, 'shin': 1, 'weather': 2, 'sweet': 3, 'one': 4, 'two': 5}"
      ]
     },
     "execution_count": 726,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "id": "c439cda8-c176-4bc3-bb46-386b805df6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sun': [0.25, 0.18181818181818182],\n",
       " 'shin': [0.25, 0.18181818181818182],\n",
       " 'weather': [0.25, 0.18181818181818182],\n",
       " 'sweet': [0.25, 0.18181818181818182],\n",
       " 'one': [0.0, 0.18181818181818182],\n",
       " 'two': [0.0, 0.09090909090909091]}"
      ]
     },
     "execution_count": 728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_weights = bnb.NaiveBayes(docs[:2], docs[:3])\n",
    "example_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "id": "66558579-2b85-4e5f-bc7c-0af71288c4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfIdf_Score(review: str, tfIdf_vector: list, weights: dict[str, list[float]], vocabulary: dict[str, int]) -> list[float]:\n",
    "    ''' Calculate the positive and negative score of the given review given the weights '''\n",
    "\n",
    "    # create the bag of words associated with the review instance\n",
    "    bag_of_words = bnb.FeatureFunction(review)\n",
    "\n",
    "    # found the positive class and negative class scores\n",
    "    positive = int()\n",
    "    negative = int()\n",
    "    for word, count in bag_of_words:\n",
    "\n",
    "        try:\n",
    "            positive += weights[word][0]*tfIdf_vector[vocabulary[word]]\n",
    "            negative += weights[word][1]*tfIdf_vector[vocabulary[word]]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # create the output list\n",
    "    output = list()\n",
    "    output.append(positive)\n",
    "    output.append(negative)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "id": "56e8af96-e4b7-4df9-8b2b-3337531e2f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.1994060174175938), np.float64(0.32715465219059725)]"
      ]
     },
     "execution_count": 733,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfIdf_Score(docs[2], tf_idf(term_frequency_vectors, vocabulary)[2], example_weights, vocabulary) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f89aa7a-bb7a-4a54-b788-a602a59790fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb.PredAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "ffae2425-0315-47f7-9ce2-018ae358c20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41227\n"
     ]
    }
   ],
   "source": [
    "word = 'shin'\n",
    "try:\n",
    "    print(training_vocabulary[word])\n",
    "except:\n",
    "    print(f'The word \"{word}\" is not in the dictionary.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "593a7fac-a79c-4a28-a435-72e798d70d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50617"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "3a133f5d-6d18-4cb8-a413-d8d8963acf57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word \"the\" is not in the dictionary.\n",
      "43816\n",
      "The word \"be\" is not in the dictionary.\n",
      "41227\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "\n",
    "bag_of_words = sp.csr_matrix((1,len(training_vocabulary)))\n",
    "feature_array = np.zeros(len(training_vocabulary))\n",
    "index = 0\n",
    "for word in [wnl.lemmatize(remove_punctuation(word), pos=\"v\") for word in docs[0].strip().lower().split()]:\n",
    "    try:\n",
    "        print(training_vocabulary[word])\n",
    "        index = training_vocabulary[word]\n",
    "        feature_array[index] = 1\n",
    "    except:\n",
    "        print(f'The word \"{word}\" is not in the dictionary.')    \n",
    "\n",
    "print(feature_array[43816])\n",
    "print(feature_array[41227])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "8c5e13b4-8a94-4d5a-8def-d17f15727b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 0 stored elements and shape (1, 50617)>"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "c23fc2f8-8889-4dc8-998a-5ad1ee73e83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0)"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_array = np.zeros(len(training_vocabulary))\n",
    "feature_array[41227] = 1\n",
    "\n",
    "feature_array[41227]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "a8d103bc-4d91-4e0f-b5f3-b4a0da665a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 0, 0],\n",
       "       [0, 1, 1, 1]])"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "docs = [[\"hello\", \"world\", \"hello\"], [\"goodbye\", \"cruel\", \"world\"]]\n",
    "indptr = [0]\n",
    "indices = []\n",
    "data = []\n",
    "vocabulary = {}\n",
    "for d in docs:\n",
    "    for term in d:\n",
    "        index = vocabulary.setdefault(term, len(vocabulary))\n",
    "        indices.append(index)\n",
    "        data.append(1)\n",
    "    indptr.append(len(indices))\n",
    "csr_matrix((data, indices, indptr), dtype=int).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "63bf9b4f-cd28-44c7-b2e0-abb535b9cf78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "66952b4b-fd2f-40bf-9d9b-7ffe72329d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 2, 3, 1]"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "fbd8b1b3-3a38-4d5c-8030-61f400e87af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3, 6]"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "824f4cdd-a275-470a-969b-77d19601b676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hello': 0, 'world': 1, 'goodbye': 2, 'cruel': 3}"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "c667fa28-1f92-43fb-939a-5c7ac5a7d32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `setdefault` not found.\n"
     ]
    }
   ],
   "source": [
    "dict().setdefault?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "c74b2884-1589-4e2f-ba3f-fa04dd52e400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.str_('\\nIsrael - Happy 45th Birthday!\\n\\n'),\n",
       " np.str_('\\nIn article <SHAIG.93Apr15220200@composer.think.com>, shaig@composer.think.com (Shai Guday) writes:\\n\\n|>    [snip]\\n|>    imagine ????  It is NOT a \"terrorist camp\" as you and the Israelis like \\n|>    to view the villages they are small communities with kids playing soccer\\n|>    in the streets, women preparing lunch, men playing cards, etc.....\\n|> \\n|> I would not argue that all or even most of the villages are \"terrorist\\n|> camps\".  There are however some which come very close to serving that\\n|> purpose and that is not to say that other did not function in that way\\n|> prior to the invasion. \\n\\nThe village I described was actually the closest I could come to\\ndescribing mine.  I agree there may be other villages where the civilian\\npopulation has deserted because it is too close to Israeli lines and\\nthus gets bombed more often.  In such villages often the only remaining \\ninhabitants are guerillas and some elderly who have nowhere else to go.\\nBut for the most part the typical South Lebanon village is more like\\nmine.  One where civilians and guerillas live together.  They are\\noften inhabiting the same house.  Many families are large, some\\nhave members of the families involved in Hizollah, most others\\nare not.  That is what is so hard of South Lebanon, Israel is\\nnot fighting an army with well drawn battle lines, but a guerilla\\ntyoe resistance which by definition and necessity blends with\\nthe local populace.  Not because they are evil cowards that\\nuse women and children as shields, but because that is the only\\nway one can fight a more powerful better equipped occupying army.\\n\\n|> Some of the villages, and yours might well be among them, are as you\\n|> describe.  Not all are.  There are a large number of groups in the area,\\n|> backed by various organizations, with a wide range of purposes.  Hizbollah\\n|> and Amal were two of the larger ones and may still be.\\n\\nHizbollah and Amal are now the main two militias.  Though\\nHizbollah people tend to be more committed to resistrance\\noperation and better motivated by religious conviction.\\n\\n  As to retaliation,\\n|> while mistakes may be made, that is still a far cry from indiscriminate\\n|> bombing, which would have produced major casualties.\\n\\nIt may be a mixture of what we both say.  Sometimes Israel chooses\\nits targets carefully.  At other times it just sends its pilots on\\nsorties aimed at a town in general since it only knows that the \\nattackers came from that specific village but has no further\\nintelligence.  On several occasions Israel retalliated against \\ncivilian refugee camps, even in North Lebanon, just to show\\nthat it will not sit idly after its soldiers have been attacked.\\nMost of the time it directs the SLA to do the dirty work and\\nindiscriminately shell some Lebanese villages on the other side.\\nI have experienced this shelling myself on several occasions,\\nthis is why the SLA militia is sometimes even more despised than \\nIsraeli troops.\\n\\n|\\n|> Well, here we disagree.  I think that Israel would willingly withdraw if\\n|> the Lebanese gov\\'t was able to field a reliable force in the area to police\\n|> it and prevent further attacks.\\n\\nI hope you are right on Israeli willingness to withdraw, but I still\\ncontend that withdrawal would be the better course for Israel\\'s\\nsecurity, since it would reduce its  military losses, and I claim\\nthat the Lebanese and Syrian gov\\'ts would be able to prevent any \\nfurther attacks on Northern Israel.\\n \\n\\n|>    There seems to be very little incentive for the Syrian and Lebanese\\n|>    goovernment to allow Hizbollah to bomb Israel proper under such \\n|>    circumstances, and now the Lebanese government has proven that it is\\n|>    capable of controlling and disarming all militias as they did\\n|>    in all other parts of Lebanon.\\n|> \\n|> No, the Syrian gov\\'t is more than happy to have Israel sink into another\\n|> Lebanese morass.  I could elaborate if necessary.\\n\\nHmm...  Here we disagree on what serves Syria interests better.\\nI think Syria wants to have Lebanon all to itself.  It would\\nbe willing to guarantee Northern Israel\\'s security in return for\\nIsraeli withdrawal.  I don\\'t think Syria wants Israel to be\\ninvolved in its protectorate of Lebanon.  Syria is sitting at the\\nnegotiating table because it has come to accept that and wants\\nto get a political resolution.  A renewal of hostilities\\nalong the Lebanese front could put the whole ME peace negotiations\\nback in question.\\n\\n\\n|>    I agree, only in the case of the Isareli soldiers their killing\\n|>    CANNOT be qualified as murder, no matter what you say.\\n|> \\n|> No, but it is regretable, as is the whole situation.\\n\\n\\nI agree that the loss of any human life is deplorable and regrettable.\\n\\n|> --\\n|> Shai Guday              | Stealth bombers,\\n|> OS Software Engineer    |\\n|> Thinking Machines Corp. |\\tthe winged ninjas of the skies.\\n|> Cambridge, MA           |\\n\\nBasil\\n')]"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_p[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962b9b4a-85ea-4d40-ac66-4af64687cb6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d441fbb-ff09-40c3-8c19-9a33d5c379cd",
   "metadata": {},
   "source": [
    "Let $x$ be a term, and let $N$ be the number of documents in the corpus.  Define $N_{0}$ and $N_{1}$ to be the number of documents the term appears in class 0 and 1 respectively.  Then, we define the **Discriminative Coefficient of the term $x$** as the following product of log-ratios:\n",
    "\n",
    "$$\\left|\\text{log}\\frac{1 + N_{0}}{1 + N_{1}}\\right| \\cdot \\text{log}\\frac{(N - N_0)(N - N_1)}{\\left|N_0 - N_1\\right| + 1}.$$\n",
    "\n",
    "We point out that the left factor in this product, being in square roots, will invert the fraction if $N_1 > N_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "id": "10d8f2c8-8c35-4e77-ba28-4450c79544df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocabulary(documents: list[str]) -> dict[str, int]:\n",
    "    '''Create the vocabulary given a list of documents.'''\n",
    "\n",
    "    # create array of unique words (put in numpy array)\n",
    "\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    from nltk.corpus import stopwords\n",
    "\n",
    "    # Create a set of stop words \n",
    "    STOP_WORDS = set(stopwords.words('english'))\n",
    "\n",
    "    stop_words = set()\n",
    "    for word in STOP_WORDS:\n",
    "        new_word = str()                                     # create a string without punctuation\n",
    "        for char in word:                                    # look at each character in the word\n",
    "            if char.isalpha():                               # determine if the character is alphabetic\n",
    "                new_word += char                             # if it is alphabetic, add it to the new word\n",
    "        if new_word != '':\n",
    "            stop_words.add(new_word)\n",
    "        \n",
    "    # instantiate important data types for storing processed data\n",
    "    # documents_array = documents\n",
    "    # documents_array = np.array(list(documents).strip().lower().split())  # list of potential words from string\n",
    "    vocab_list = list()                                                # dictionary for holding word counts\n",
    "\n",
    "    # Initialize wordnet lemmatizer\n",
    "    wnl = WordNetLemmatizer()\n",
    "    \n",
    "    # consider each word, determine if any of its characters are not alphabetic\n",
    "    for doc in documents:\n",
    "        # print(doc)\n",
    "        for word in doc.strip().lower().split():\n",
    "            # print(word)\n",
    "            new_word = str()                                     # create a string without punctuation\n",
    "            for char in word:                                    # look at each character in the word\n",
    "                if char.isalpha():                               # determine if the character is alphabetic\n",
    "                    new_word += char                             # if it is alphabetic, add it to the new word\n",
    "            if new_word != '':                                   # make sure the new string is not empty\n",
    "\n",
    "                newer_word = wnl.lemmatize(new_word, pos=\"v\")    # lemetize the word\n",
    "                if newer_word not in stop_words:                 # check that the new word is not a common word listed in the stop words\n",
    "            \n",
    "                # update the word count for the new word\n",
    "                    if newer_word not in vocab_list:             # determine if the new_word has been counted\n",
    "                        vocab_list.append(newer_word)\n",
    "                \n",
    "    # output = list()                                          # list of (word, count) tuples\n",
    "    # for word in dict_counts:\n",
    "    #     output.append((word, dict_counts[word]))\n",
    "\n",
    "\n",
    "    # order alphabetically the elements in the array\n",
    "    vocab_array = np.array(vocab_list)\n",
    "    vocab_array.sort()\n",
    "\n",
    "    # create a dictionary of the elements\n",
    "    vocab_dict = dict()\n",
    "    for index in range(len(vocab_array)):\n",
    "        vocab_dict[vocab_array[index]] = index\n",
    "    \n",
    "    return vocab_dict\n",
    "    \n",
    "def discriminative_coefficients(pos_reviews: list[str], neg_reviews: list[str], vocab: dict[str, float]) -> float:\n",
    "\n",
    "    N = len(pos_reviews+neg_reviews)\n",
    "    # create a vocabulary for pos_reviews\n",
    "    pos_vocabulary = vocabulary(pos_reviews)\n",
    "    print(pos_vocabulary)\n",
    "\n",
    "    # create a vocabulary for neg_reviews\n",
    "    neg_vocabulary = vocabulary(neg_reviews)\n",
    "    # print(neg_vocabulary)\n",
    "    \n",
    "    return pos_vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "id": "1030eac2-9ade-41c7-8446-7ca3ebf57706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{np.str_('birthday'): 0, np.str_('happy'): 1, np.str_('israel'): 2, np.str_('th'): 3}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{np.str_('birthday'): 0,\n",
       " np.str_('happy'): 1,\n",
       " np.str_('israel'): 2,\n",
       " np.str_('th'): 3}"
      ]
     },
     "execution_count": 697,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficients = discriminative_coefficients(train_p[:1], train_s[:1], vocabulary)\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "d2d947fb-e091-46a6-9214-507973a09369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FeatureList(documents: list[str]) -> list[list]:\n",
    "    stop_words = create_stopwords()\n",
    "    docs_list = list()\n",
    "    new_feature_list = list()\n",
    "    for item in documents:\n",
    "        for word in item.strip().lower().split():\n",
    "            new_word = lemmatize(remove_punctuation(word))\n",
    "            if new_word not in stop_words and new_word != '':\n",
    "                new_feature_list.append(new_word)\n",
    "    docs_list.append(new_feature_list)\n",
    "    \n",
    "    return docs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "id": "29834b56-ac62-466a-a898-0e76f7f67676",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In article <rdippold.735426379@qualcom> \n",
      "(Ron \"Asbestos\" Dippold) writes: \n",
      "  ...\n",
      "> The only thing that worries me is that 2:1 compression - the\n",
      "> SoundBlaster can do it automatically in hardware, but other than that\n",
      "> I don't have a good feel for how processor intensive it is, so I can't\n",
      "> estimate how fast a PC you'd need.\n",
      "\n",
      "        There's a better way. Doesn't Qualcom have a secure design\n",
      "        that it decided not to market?  Since they aren't going to\n",
      "        use it, wouldn't the patriotic thing be to put the design in\n",
      "        the public domain? How about selling a \"Cryptography\n",
      "        Educational Kit\" with the critical parts? Something that could\n",
      "        end up as a PC option board with two phone jacks?\n",
      "\n",
      "        Cheers,\n",
      "                Marc\n",
      "\n",
      "---\n",
      " Marc Thibault                             | marc@tanda.isis.org\n",
      " Automation Architect                      | CIS:71441,2226\n",
      " R.R.1, Oxford Mills, Ontario, Canada      | NC FreeNet: aa185\n",
      "\n",
      "-----BEGIN PGP PUBLIC KEY BLOCK-----\n",
      "mQBNAiqxYTkAAAECALfeHYp0yC80s1ScFvJSpj5eSCAO+hihtneFrrn+vuEcSavh\n",
      "AAUwpIUGyV2N8n+lFTPnnLc42Ms+c8PJUPYKVI8ABRG0I01hcmMgVGhpYmF1bHQg\n",
      "PG1hcmNAdGFuZGEuaXNpcy5vcmc+\n",
      "=HLnv\n",
      "-----END PGP PUBLIC KEY BLOCK-----\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train_s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "1748bb43-a9c3-45b8-b252-3e136e8664d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-10000, -10.955348846514784]"
      ]
     },
     "execution_count": 663,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PvsS_weights['pghcmnadgfuzgeuaxnpcyvcmc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "5484497e-7a69-46a7-8467-6189d84e53f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-150590.2003700718, -696.6277004778442]"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.Score(train_s[0], PvsS_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "8ecdc7c1-635d-4bf7-b4e4-36afff0530a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50617"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "dfada32e-cb82-4f55-b5c5-54435dc255ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33762"
      ]
     },
     "execution_count": 662,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_vocabulary['pghcmnadgfuzgeuaxnpcyvcmc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "a6e0dc38-7cdb-4212-8883-3058fb327c95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['article',\n",
       "  'rdippoldqualcom',\n",
       "  'ron',\n",
       "  'asbestos',\n",
       "  'dippold',\n",
       "  'write',\n",
       "  'thing',\n",
       "  'worry',\n",
       "  'compression',\n",
       "  'soundblaster',\n",
       "  'automatically',\n",
       "  'hardware',\n",
       "  'good',\n",
       "  'feel',\n",
       "  'processor',\n",
       "  'intensive',\n",
       "  'cant',\n",
       "  'estimate',\n",
       "  'fast',\n",
       "  'pc',\n",
       "  'need',\n",
       "  'theres',\n",
       "  'better',\n",
       "  'way',\n",
       "  'qualcom',\n",
       "  'secure',\n",
       "  'design',\n",
       "  'decide',\n",
       "  'market',\n",
       "  'since',\n",
       "  'go',\n",
       "  'use',\n",
       "  'patriotic',\n",
       "  'thing',\n",
       "  'put',\n",
       "  'design',\n",
       "  'public',\n",
       "  'domain',\n",
       "  'sell',\n",
       "  'cryptography',\n",
       "  'educational',\n",
       "  'kit',\n",
       "  'critical',\n",
       "  'part',\n",
       "  'something',\n",
       "  'could',\n",
       "  'end',\n",
       "  'pc',\n",
       "  'option',\n",
       "  'board',\n",
       "  'two',\n",
       "  'phone',\n",
       "  'jack',\n",
       "  'cheer',\n",
       "  'marc',\n",
       "  'marc',\n",
       "  'thibault',\n",
       "  'marctandaisisorg',\n",
       "  'automation',\n",
       "  'architect',\n",
       "  'cis',\n",
       "  'rr',\n",
       "  'oxford',\n",
       "  'mill',\n",
       "  'ontario',\n",
       "  'canada',\n",
       "  'nc',\n",
       "  'freenet',\n",
       "  'aa',\n",
       "  'begin',\n",
       "  'pgp',\n",
       "  'public',\n",
       "  'key',\n",
       "  'block',\n",
       "  'mqbnaiqxytkaaaecalfehypycsscfvjspjescaohihtnefrrnvuecsavh',\n",
       "  'aauwpiugyvnnlftpnnlcmscpjupykviabrgihcmmgvghpymfbhqg',\n",
       "  'pghcmnadgfuzgeuaxnpcyvcmc',\n",
       "  'hlnv',\n",
       "  'end',\n",
       "  'pgp',\n",
       "  'public',\n",
       "  'key',\n",
       "  'block']]"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FeatureList(train_s[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "id": "6dab8cfe-fbcc-42d2-bcbc-ac4270590cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('israel', 1), ('happy', 1), ('th', 1), ('birthday', 1)]"
      ]
     },
     "execution_count": 646,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.FeatureFunction(train_p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "d7ebdc0f-04c1-42f9-8bb6-de69dea03e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.str_('\\nIn article <rdippold.735426379@qualcom> \\n(Ron \"Asbestos\" Dippold) writes: \\n  ...\\n> The only thing that worries me is that 2:1 compression - the\\n> SoundBlaster can do it automatically in hardware, but other than that\\n> I don\\'t have a good feel for how processor intensive it is, so I can\\'t\\n> estimate how fast a PC you\\'d need.\\n\\n        There\\'s a better way. Doesn\\'t Qualcom have a secure design\\n        that it decided not to market?  Since they aren\\'t going to\\n        use it, wouldn\\'t the patriotic thing be to put the design in\\n        the public domain? How about selling a \"Cryptography\\n        Educational Kit\" with the critical parts? Something that could\\n        end up as a PC option board with two phone jacks?\\n\\n        Cheers,\\n                Marc\\n\\n---\\n Marc Thibault                             | marc@tanda.isis.org\\n Automation Architect                      | CIS:71441,2226\\n R.R.1, Oxford Mills, Ontario, Canada      | NC FreeNet: aa185\\n\\n-----BEGIN PGP PUBLIC KEY BLOCK-----\\nmQBNAiqxYTkAAAECALfeHYp0yC80s1ScFvJSpj5eSCAO+hihtneFrrn+vuEcSavh\\nAAUwpIUGyV2N8n+lFTPnnLc42Ms+c8PJUPYKVI8ABRG0I01hcmMgVGhpYmF1bHQg\\nPG1hcmNAdGFuZGEuaXNpcy5vcmc+\\n=HLnv\\n-----END PGP PUBLIC KEY BLOCK-----\\n\\n')]"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_s[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "7377b54d-3b02-4340-87b7-d0b022ec316e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(word: str) -> str:\n",
    "\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    from nltk.corpus import stopwords    \n",
    "    \n",
    "    new_word = str()                                     # create a string without punctuation\n",
    "    for char in word:                                    # look at each character in the word\n",
    "        if char.isalpha():                               # determine if the character is alphabetic\n",
    "            new_word += char                             # if it is alphabetic, add it to the new word\n",
    "\n",
    "    return new_word\n",
    "\n",
    "def lemmatize(word: str) -> str:\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    wnl = WordNetLemmatizer()\n",
    "    new_word = wnl.lemmatize(word, pos=\"v\")\n",
    "    return new_word\n",
    "\n",
    "def create_stopwords() -> str:\n",
    "    from nltk.corpus import stopwords\n",
    "\n",
    "    # Create a set of stop words \n",
    "    STOP_WORDS = set(stopwords.words('english'))\n",
    "\n",
    "    stop_words = set()\n",
    "    for word in STOP_WORDS:\n",
    "        new_word = str()                                     # create a string without punctuation\n",
    "        for char in word:                                    # look at each character in the word\n",
    "            if char.isalpha():                               # determine if the character is alphabetic\n",
    "                new_word += char                             # if it is alphabetic, add it to the new word\n",
    "        if new_word != '':\n",
    "            stop_words.add(new_word)\n",
    "\n",
    "    return stop_words\n",
    "\n",
    "    \n",
    "    # if new_word != '':                                   # make sure the new string is not empty\n",
    "\n",
    "    #     newer_word = wnl.lemmatize(new_word, pos=\"v\")    # lemetize the word\n",
    "    #     if newer_word not in stop_words:                 # check that the new word is not a common word listed in the stop words\n",
    "    #         return newer_word\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cbed0f-7263-4d2e-b1b7-bcc9571633a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0170aa62-3b0f-4ad1-b23b-156bcf030537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c84e724-c6ce-44ef-999b-492ff266013a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "id": "4de1476b-60fd-484e-9c64-df2e558f768e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 699,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize(\"cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "id": "4d9bf7b7-8b48-45a8-8290-ba5aee3b5203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "id": "045202c7-5bf2-4d40-bd84-038ed38e033d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(word = \"cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "id": "eaa1a0ed-cf4c-460e-bee2-85189a13e93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 707,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize('cats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "id": "2d63ad89-4c47-446c-85ec-caa9cbc23f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('israel', 1), ('happy', 1), ('th', 1), ('birthday', 1)]"
      ]
     },
     "execution_count": 738,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.FeatureFunction(train_p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "id": "7d818f9b-583b-4c06-ac30-aa61ed9b346a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[740], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "# train_p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "id": "d6d7f4c6-b4ae-49a3-b8fd-62cffa022522",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spacy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[741], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m spacy\u001b[38;5;241m.\u001b[39mdownload()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spacy' is not defined"
     ]
    }
   ],
   "source": [
    "spacy.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "id": "7c7b928d-98a9-4438-94e3-b54b046d872b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/blakewallace/anaconda3/envs/linear_regression_env/bin/python'"
      ]
     },
     "execution_count": 742,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "id": "fe1268db-565f-40a1-84d5-b6812c821de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Using cached spacy-3.8.2.tar.gz (1.3 MB)\n",
      "  Installing build dependencies ... \u001b[?25l-^C\n",
      "\u001b[?25canceled\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!/Users/blakewallace/anaconda3/envs/linear_regression_env/bin/python -m pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbf86d9-92b8-4508-a182-4cad26dfbcec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
