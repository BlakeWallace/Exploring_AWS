{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2cf310d-e17a-4102-b3bd-72627292155c",
   "metadata": {},
   "source": [
    "# Part of Speech Tokenizer, Politics Data\n",
    "\n",
    "Notebook following the sentence tokenizer work.\n",
    "\n",
    "This notebook builds on the data cleaning and preparing tasks.  It assumes a sentence tokenizer, and walks through the process of removing words using Parts of Speech tagging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efce1c5-8583-42ff-b765-74de88d19c05",
   "metadata": {},
   "source": [
    "# Contents\n",
    "\n",
    "1. [Functions](#Functions)\n",
    "    1. [cleanFile](#Clean-File-Function)\n",
    "    2. [sentTokenizer](#Sentence-Tokenizer-Function)\n",
    "    3. [Example Applying `cleanFile` and `sentTokenizer`](#Example-Applying-cleanFile-and-sentTokenizer)\n",
    "        1. [Example file, `124146.txt`](#Example-file,-124146.txt)\n",
    "        2. [Apply `cleanFile` function](#Apply-cleanFile-function)\n",
    "        3. [Apply `sentTokenizer`](#Apply-sentTokenizer)\n",
    "1. [Part of Speech Tagging](#Part-of-Speech-Tagging)\n",
    "    1. [Create pos tagged sentences](#Create-pos-tagged-sentences)\n",
    "    2. [Remove specific tags](#Remove-the-following-tags)\n",
    "    3. [Lemmatize Words, Remove Punctuationa and Stopwords](#Lemmatize-Words,-Remove-Punctuationa-and-Stopwords)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac31c4f-a92d-4002-9b23-d2ed2cd7da68",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fba5d2-f672-4226-87f7-4e1ab302dc86",
   "metadata": {},
   "source": [
    "### Clean File Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fc345db-e896-4865-b251-eee60b023a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanFile(fname: str) -> str:\n",
    "    # tname = input('Enter the text file name: ')\n",
    "    clean_file_text = ''\n",
    "    fhand = open(fname)\n",
    "    for line in fhand:\n",
    "        new_line = ''\n",
    "        if line.find('@') != -1: continue \n",
    "        elif line.find('Host') != -1: continue \n",
    "        elif line.find('User') != -1: continue\n",
    "        elif line.find('VAX') != -1: continue\n",
    "        elif line.find('USPS Mail:') != -1: continue \n",
    "        elif line.find('UUCP:') != -1: continue\n",
    "        elif line.find('P.O. Box') != -1: continue\n",
    "        else: \n",
    "            new_line = line.replace('[IC]', '').replace('\\n', ' ').replace('e.g.', ' ')\n",
    "\n",
    "        # other characters encountered in the dataset but removed by the string.isalpha() method below\n",
    "            # '>', '').replace(\n",
    "            # '+', '').replace(\n",
    "            # '-', '').replace(\n",
    "            # '#', '').replace(\n",
    "            # '*', '').replace(\n",
    "            # '^', '').replace(\n",
    "            # '|', '').replace(\n",
    "            # '/', ' ').replace(\n",
    "            # '_', ' ').replace(\n",
    "            \n",
    "    # clean each string of all non-alphabetic characters except common punctuation\n",
    "        clean_line = str()\n",
    "        for char in new_line:\n",
    "            if char in ['.', '!', '?', ',']:\n",
    "                clean_line += char\n",
    "            elif char == \"'\":\n",
    "                clean_line += ''\n",
    "            elif char.isalpha():\n",
    "                clean_line += char\n",
    "            else:\n",
    "                clean_line += ' '\n",
    "        clean_file_text += clean_line\n",
    "        \n",
    "    return clean_file_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ff84bb-e740-40d3-9310-3f984552bdc8",
   "metadata": {},
   "source": [
    "### Sentence Tokenizer Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "828b192b-0bc3-413d-9dc5-e1218ea66038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentTokenizer(cleanFile: str) -> list[str]:\n",
    "    from nltk.tokenize import sent_tokenize\n",
    "\n",
    "    sentences = sent_tokenize(cleanFile.strip())\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78feb09-9891-45ee-bae7-5769d0e3f828",
   "metadata": {},
   "source": [
    "### Example Applying `cleanFile` and `sentTokenizer`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ce5579-0682-4c73-92b0-380d385048d2",
   "metadata": {},
   "source": [
    "#### Example file, `124146.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f47d6a3e-8b13-4929-a383-a3e6ec6ba2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nntp-Posting-Host: acvax1\n",
      "\n",
      "Nntp-Posting-User: cvads008\n",
      "\n",
      "\n",
      "\n",
      "visser@convex.com (Lance Visser) writes:\n",
      "\n",
      "> +>I can't find my source.\n",
      "\n",
      "> +>But.  If you state that you will retract your claim, I'll go dig one up\n",
      "\n",
      "> +>at the library.  Fair enough?\n",
      "\n",
      "> \n",
      "\n",
      "> \tARE YOU SERIOUS?  I'm not talking about retracting anything until\n",
      "\n",
      "> you have produced SOMETHING.\n",
      "\n",
      "> \n",
      "\n",
      "> \tIf you were not just talking off the top of your head, I would\n",
      "\n",
      "> assume that you have SOME memory of what your source is.\n",
      "\n",
      "> \n",
      "\n",
      "> \tPUT UP NOW without conditions!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Yes, very serious.  I claim that I can substantiate my statement that\n",
      "\n",
      "Rudman says he doesn't believe Perot was investigating him.  You claim\n",
      "\n",
      "Perot was investigating him.  If you will state that you were in error\n",
      "\n",
      "on this point, provided I produce the source, I'll go dig it up.\n",
      "\n",
      "\n",
      "\n",
      "Now give me one reason why I should go to the trouble if you won't\n",
      "\n",
      "agree to this?  It is simple enough you know.  But I don't have time\n",
      "\n",
      "to waste if you'll just blow it off with more of the tripe you usually\n",
      "\n",
      "post.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "Michael Pye\n",
      "\n",
      "email: mpye@csupomona.edu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print each line of raw file\n",
    "fhand = open('./data/kaggle/Text_Classification_on_Documents/Politics/124146.txt')\n",
    "for line in fhand:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e508ab-94c9-445f-aadd-aade423874dc",
   "metadata": {},
   "source": [
    "#### Apply `cleanFile` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acf560bc-83f1-4a68-bb2a-5666c9973848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'     I cant find my source.     But.  If you state that you will retract your claim, Ill go dig one up     at the library.  Fair enough?       ARE YOU SERIOUS?  Im not talking about retracting anything until   you have produced SOMETHING.       If you were not just talking off the top of your head, I would   assume that you have SOME memory of what your source is.       PUT UP NOW without conditions!   Yes, very serious.  I claim that I can substantiate my statement that Rudman says he doesnt believe Perot was investigating him.  You claim Perot was investigating him.  If you will state that you were in error on this point, provided I produce the source, Ill go dig it up.  Now give me one reason why I should go to the trouble if you wont agree to this?  It is simple enough you know.  But I dont have time to waste if youll just blow it off with more of the tripe you usually post.        Michael Pye '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanFile('./data/kaggle/Text_Classification_on_Documents/Politics/124146.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2969c6-c0ff-4e66-bbc7-653cf2a1a060",
   "metadata": {},
   "source": [
    "#### Apply `sentTokenizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4ebea88-5cd2-4887-a872-946bffbdbff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I cant find my source.',\n",
       " 'But.',\n",
       " 'If you state that you will retract your claim, Ill go dig one up     at the library.',\n",
       " 'Fair enough?',\n",
       " 'ARE YOU SERIOUS?',\n",
       " 'Im not talking about retracting anything until   you have produced SOMETHING.',\n",
       " 'If you were not just talking off the top of your head, I would   assume that you have SOME memory of what your source is.',\n",
       " 'PUT UP NOW without conditions!',\n",
       " 'Yes, very serious.',\n",
       " 'I claim that I can substantiate my statement that Rudman says he doesnt believe Perot was investigating him.',\n",
       " 'You claim Perot was investigating him.',\n",
       " 'If you will state that you were in error on this point, provided I produce the source, Ill go dig it up.',\n",
       " 'Now give me one reason why I should go to the trouble if you wont agree to this?',\n",
       " 'It is simple enough you know.',\n",
       " 'But I dont have time to waste if youll just blow it off with more of the tripe you usually post.',\n",
       " 'Michael Pye']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleanFile -> sentTokenizer\n",
    "sentTokenizer(cleanFile('./data/kaggle/Text_Classification_on_Documents/Politics/124146.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d413771-2d4e-4aed-8bc1-520a89b654d8",
   "metadata": {},
   "source": [
    "## Part of Speech Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae30957c-3c7b-44f2-83ad-d360ade47975",
   "metadata": {},
   "source": [
    "### Create pos tagged sentences\n",
    "\n",
    "Note, here a simple string.split() method is being applied.  An alternative could be to apply nltk.word_tokenize to each sentence.  This might be an alternative if the accuracy is low and tuning is needed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bf3fdcd-05fb-466c-8b28-0741f1edbbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('I', 'PRP'), ('cant', 'VBP'), ('find', 'VB'), ('my', 'PRP$'), ('source.', 'NN')], [('But.', 'NN')], [('If', 'IN'), ('you', 'PRP'), ('state', 'NN'), ('that', 'IN'), ('you', 'PRP'), ('will', 'MD'), ('retract', 'VB'), ('your', 'PRP$'), ('claim,', 'NN'), ('Ill', 'NNP'), ('go', 'VBP'), ('dig', 'RB'), ('one', 'CD'), ('up', 'NN'), ('at', 'IN'), ('the', 'DT'), ('library.', 'NN')], [('Fair', 'NNP'), ('enough?', 'NN')], [('ARE', 'NNP'), ('YOU', 'NNP'), ('SERIOUS?', 'NNP')], [('Im', 'NNP'), ('not', 'RB'), ('talking', 'VBG'), ('about', 'IN'), ('retracting', 'VBG'), ('anything', 'NN'), ('until', 'IN'), ('you', 'PRP'), ('have', 'VBP'), ('produced', 'VBN'), ('SOMETHING.', 'NNP')], [('If', 'IN'), ('you', 'PRP'), ('were', 'VBD'), ('not', 'RB'), ('just', 'RB'), ('talking', 'VBG'), ('off', 'RP'), ('the', 'DT'), ('top', 'NN'), ('of', 'IN'), ('your', 'PRP$'), ('head,', 'NN'), ('I', 'PRP'), ('would', 'MD'), ('assume', 'VB'), ('that', 'IN'), ('you', 'PRP'), ('have', 'VBP'), ('SOME', 'NNP'), ('memory', 'NN'), ('of', 'IN'), ('what', 'WP'), ('your', 'PRP$'), ('source', 'NN'), ('is.', 'NN')], [('PUT', 'VB'), ('UP', 'RP'), ('NOW', 'NNP'), ('without', 'IN'), ('conditions!', 'NN')], [('Yes,', 'JJ'), ('very', 'RB'), ('serious.', 'JJ')], [('I', 'PRP'), ('claim', 'VBP'), ('that', 'IN'), ('I', 'PRP'), ('can', 'MD'), ('substantiate', 'VB'), ('my', 'PRP$'), ('statement', 'NN'), ('that', 'IN'), ('Rudman', 'NNP'), ('says', 'VBZ'), ('he', 'PRP'), ('doesnt', 'VBZ'), ('believe', 'VBP'), ('Perot', 'NNP'), ('was', 'VBD'), ('investigating', 'VBG'), ('him.', 'NN')], [('You', 'PRP'), ('claim', 'VBP'), ('Perot', 'NNP'), ('was', 'VBD'), ('investigating', 'VBG'), ('him.', 'NN')], [('If', 'IN'), ('you', 'PRP'), ('will', 'MD'), ('state', 'NN'), ('that', 'IN'), ('you', 'PRP'), ('were', 'VBD'), ('in', 'IN'), ('error', 'NN'), ('on', 'IN'), ('this', 'DT'), ('point,', 'NN'), ('provided', 'VBD'), ('I', 'PRP'), ('produce', 'VBP'), ('the', 'DT'), ('source,', 'NN'), ('Ill', 'NNP'), ('go', 'VBP'), ('dig', 'VB'), ('it', 'PRP'), ('up.', 'JJ')], [('Now', 'RB'), ('give', 'VB'), ('me', 'PRP'), ('one', 'CD'), ('reason', 'NN'), ('why', 'WRB'), ('I', 'PRP'), ('should', 'MD'), ('go', 'VB'), ('to', 'TO'), ('the', 'DT'), ('trouble', 'NN'), ('if', 'IN'), ('you', 'PRP'), ('wont', 'VBP'), ('agree', 'JJ'), ('to', 'TO'), ('this?', 'VB')], [('It', 'PRP'), ('is', 'VBZ'), ('simple', 'JJ'), ('enough', 'RB'), ('you', 'PRP'), ('know.', 'VBP')], [('But', 'CC'), ('I', 'PRP'), ('dont', 'VBP'), ('have', 'VBP'), ('time', 'NN'), ('to', 'TO'), ('waste', 'VB'), ('if', 'IN'), ('youll', 'JJ'), ('just', 'RB'), ('blow', 'VB'), ('it', 'PRP'), ('off', 'RP'), ('with', 'IN'), ('more', 'JJR'), ('of', 'IN'), ('the', 'DT'), ('tripe', 'NN'), ('you', 'PRP'), ('usually', 'RB'), ('post.', 'VBP')], [('Michael', 'NNP'), ('Pye', 'NNP')]]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "sentences = sentTokenizer(cleanFile('./data/kaggle/Text_Classification_on_Documents/Politics/124146.txt'))\n",
    "tagged_word_sentences = nltk.pos_tag_sents([sent.split() for sent in sentences])\n",
    "print(tagged_word_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efbadc8-4443-4975-8215-379c44c59e8c",
   "metadata": {},
   "source": [
    "### Remove the following tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613303ff-ecf0-470d-a0a2-d74b3e922ff3",
   "metadata": {},
   "source": [
    "Source of Tags list: [blog](https://www.learntek.org/blog/categorizing-pos-tagging-nltk-python/#:~:text=CC%20coordinating%20conjunction)\n",
    "\n",
    "- IN preposition/subordinating conjunction  \n",
    "- NNP proper noun, singular ‘Harrison’  \n",
    "- NNPS proper noun, plural ‘Americans’  \n",
    "- PRP personal pronoun I, he, she\n",
    "- PRP\\$ possessive pronoun my, his, hers  \n",
    "- WP wh-pronoun who, what  \n",
    "- WP\\$ possessive wh-pronoun whose  \n",
    "- WRB wh-abverb where, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04744a25-81c0-4224-81eb-7e887baf73c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP'), ('cant', 'VBP'), ('find', 'VB'), ('my', 'PRP$'), ('source.', 'NN')]\n",
      "[('But.', 'NN')]\n",
      "[('If', 'IN'), ('you', 'PRP'), ('state', 'NN'), ('that', 'IN'), ('you', 'PRP'), ('will', 'MD'), ('retract', 'VB'), ('your', 'PRP$'), ('claim,', 'NN'), ('Ill', 'NNP'), ('go', 'VBP'), ('dig', 'RB'), ('one', 'CD'), ('up', 'NN'), ('at', 'IN'), ('the', 'DT'), ('library.', 'NN')]\n",
      "[('Fair', 'NNP'), ('enough?', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "sentences = sentTokenizer(cleanFile('./data/kaggle/Text_Classification_on_Documents/Politics/124146.txt'))\n",
    "tagged_word_sentences = nltk.pos_tag_sents([sent.split() for sent in sentences])\n",
    "for sentence in tagged_word_sentences[:4]:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb2eee35-6284-4d8c-8114-86f1ebe5c754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I PRP\n",
      "cant VBP\n",
      "find VB\n",
      "my PRP$\n",
      "source. NN\n",
      " cant find source.\n",
      "But. NN\n",
      " But.\n",
      "If IN\n",
      "you PRP\n",
      "state NN\n",
      "that IN\n",
      "you PRP\n",
      "will MD\n",
      "retract VB\n",
      "your PRP$\n",
      "claim, NN\n",
      "Ill NNP\n",
      "go VBP\n",
      "dig RB\n",
      "one CD\n",
      "up NN\n",
      "at IN\n",
      "the DT\n",
      "library. NN\n",
      " state will retract claim, go dig one up the library.\n",
      "Fair NNP\n",
      "enough? NN\n",
      " enough?\n",
      "  cant find source.  But.  state will retract claim, go dig one up the library.  enough?\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "sentences = sentTokenizer(cleanFile('./data/kaggle/Text_Classification_on_Documents/Politics/124146.txt'))\n",
    "tagged_word_sentences = nltk.pos_tag_sents([sent.split() for sent in sentences])\n",
    "new_document = str()\n",
    "for sentence in tagged_word_sentences[:4]:\n",
    "    # print(sentence)\n",
    "    new_sentence = str()\n",
    "    for word, tag in sentence:\n",
    "        print(word, tag)\n",
    "        if tag not in ['IN', 'NNP', 'NNPS', 'PRP', 'PRP$', 'WP', 'WP$', 'WRB']:\n",
    "            new_sentence += ' '+word\n",
    "    new_document += ' '+new_sentence\n",
    "    # print(new_sentence.lstrip())\n",
    "    print(new_sentence)\n",
    "\n",
    "print(new_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "832f71c7-6cb5-43da-85f0-ea49fff97296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cant find source. But. state will retract claim, go dig one up the library. enough?  not talking retracting anything have produced were not just talking off the top head, would assume have memory source is. PUT UP conditions! Yes, very serious. claim can substantiate statement says doesnt believe was investigating him. claim was investigating him. will state were error this point, provided produce the source, go dig up. Now give one reason should go to the trouble wont agree to this? is simple enough know. But dont have time to waste youll just blow off more the tripe usually post. \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "sentences = sentTokenizer(cleanFile('./data/kaggle/Text_Classification_on_Documents/Politics/124146.txt'))\n",
    "tagged_word_sentences = nltk.pos_tag_sents([sent.split() for sent in sentences])\n",
    "new_document = str()\n",
    "for sentence in tagged_word_sentences:\n",
    "    # print(sentence)\n",
    "    new_sentence = str()\n",
    "    for word, tag in sentence:\n",
    "        # print(word, tag)\n",
    "        if tag not in ['IN', 'NNP', 'NNPS', 'PRP', 'PRP$', 'WP', 'WP$', 'WRB']:\n",
    "            new_sentence += ' '+word\n",
    "    new_document += ' '+new_sentence.lstrip()\n",
    "    # print(new_sentence.lstrip())\n",
    "    # print(new_sentence)\n",
    "\n",
    "print(new_document.lstrip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84980848-5442-4ebc-8926-10d3ee0ed59c",
   "metadata": {},
   "source": [
    "### Second Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae59dcaf-aaa9-4528-a3f2-0d11027b4293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In article <1qk73q$3fj@agate.berkeley.edu> dzkriz@ocf.berkeley.edu (Dennis Kriz) writes:\n",
      ">In article <sandvik-140493233557@sandvik-kent.apple.com> sandvik@newton.apple.com (Kent Sandvik) writes:\n",
      ">>In article <1qid8s$ik0@agate.berkeley.edu>, dzkriz@ocf.berkeley.edu (Dennis\n",
      ">>Kriz) wrote:\n",
      ">>> The most recent reason given by the Clinton Administration for\n",
      ">>> calling for federally funded abortions is that many private\n",
      ">>> health insurance programs offer coverage for abortion.\n",
      ">>\n",
      ">>> The following are two form letters regarding this.  Please send\n",
      ">>> them around to friends as well as other BBSs\n",
      ">>\n",
      ">>\"Just sign it and send it, sonny, don't read the fine print. Just\n",
      ">>sign it, sonny! :-).\n",
      ">>\n",
      ">>Cheers,\n",
      ">>Kent\n",
      ">>---\n",
      ">>sandvik@newton.apple.com. ALink: KSAND -- Private activities on the net.\n",
      ">\n",
      ">\n",
      ">Well you know that you're getting somewhere, when you start getting\n",
      ">responses like this.\n",
      ">\n",
      ">Kent, let me explain it to you.\n",
      ">\n",
      ">If you are paying for a phone, and you don't want call-waiting, YOU DON'T\n",
      ">NEED TO PAY FOR CALl-WAITING.\n",
      ">\n",
      ">This whole Clinton induced abortion debate SHOULD begin to make NARAL\n",
      ">nervous, because it has exposed a real scam.\n",
      ">\n",
      ">If one is paying for a PRIVATE health insurance plan and DOES NOT WANT\n",
      ">\"abortion coverage\" there is NO reason for that person to be COMPLELLED\n",
      ">to pay for it.  (Just as one should not be compelled to pay for lipposuction\n",
      ">coverage if ONE doesn't WANT that kind of coverage).\n",
      "\n",
      "There are \"basic services\" and there are \"optional services\", Dennis. Call\n",
      "waiting is an optional service, but having the number \"3\" work on one's phone\n",
      "is a basic service. Just because some nutcase doesn't happen to use the \"3\"\n",
      "on his phone, since none of the numbers he calls has a \"3\" in it, doesn't mean\n",
      "that he has the right to demand that the phone company \"unbundle\" the charges\n",
      "for the use of each phone digit; an unbundling that would be horrendously\n",
      "inefficient because of all the billing & bookkeeping overhead. Similarly,\n",
      "abortion can be seen as a \"basic service\".\n",
      "\n",
      "Furthermore, public funding of abortion SAVES money, as well as being, in the\n",
      "views of a substantial portion of the population, probably a clear majority,\n",
      "an ethical thing to do. If you don't like saving money on your taxes in that\n",
      "way, why don't you take the taxes you save and invest in private charities\n",
      "with programs that help reduce the NEED for abortion. If every pro-lifer did\n",
      "the same, it would create a massive economic negative feedback loop which\n",
      "would all but ELIMINATE the need for public funding of abortion. Then you\n",
      "would get your wish. And, you know what? No pro-choicer I know would stop\n",
      "you carrying out that plan. They might even HELP you with it...\n",
      "\n",
      "\t\t\t\t\t\t\t\t- Kevin\n"
     ]
    }
   ],
   "source": [
    "# print each line of raw file, without 'new lines' (\\n)\n",
    "fhand = open('./data/kaggle/Text_Classification_on_Documents/Politics/178444.txt')\n",
    "for line in fhand:\n",
    "    print(line.rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70c25dc3-6c5b-495a-ae0b-91acae36571e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   Kriz  wrote      The most recent reason given by the Clinton Administration for     calling for federally funded abortions is that many private     health insurance programs offer coverage for abortion.         The following are two form letters regarding this.  Please send     them around to friends as well as other BBSs       Just sign it and send it, sonny, dont read the fine print. Just   sign it, sonny!    .      Cheers,   Kent            Well you know that youre getting somewhere, when you start getting  responses like this.    Kent, let me explain it to you.    If you are paying for a phone, and you dont want call waiting, YOU DONT  NEED TO PAY FOR CALl WAITING.    This whole Clinton induced abortion debate SHOULD begin to make NARAL  nervous, because it has exposed a real scam.    If one is paying for a PRIVATE health insurance plan and DOES NOT WANT   abortion coverage  there is NO reason for that person to be COMPLELLED  to pay for it.   Just as one should not be compelled to pay for lipposuction  coverage if ONE doesnt WANT that kind of coverage .  There are  basic services  and there are  optional services , Dennis. Call  waiting is an optional service, but having the number     work on ones phone is a basic service. Just because some nutcase doesnt happen to use the     on his phone, since none of the numbers he calls has a     in it, doesnt mean  that he has the right to demand that the phone company  unbundle  the charges for the use of each phone digit  an unbundling that would be horrendously inefficient because of all the billing   bookkeeping overhead. Similarly,  abortion can be seen as a  basic service .  Furthermore, public funding of abortion SAVES money, as well as being, in the  views of a substantial portion of the population, probably a clear majority,  an ethical thing to do. If you dont like saving money on your taxes in that  way, why dont you take the taxes you save and invest in private charities  with programs that help reduce the NEED for abortion. If every pro lifer did  the same, it would create a massive economic negative feedback loop which  would all but ELIMINATE the need for public funding of abortion. Then you  would get your wish. And, you know what? No pro choicer I know would stop you carrying out that plan. They might even HELP you with it...            Kevin '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanFile('./data/kaggle/Text_Classification_on_Documents/Politics/178444.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2ee69c1-ee98-4b98-92aa-a182d7a55b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kriz  wrote      The most recent reason given by the Clinton Administration for     calling for federally funded abortions is that many private     health insurance programs offer coverage for abortion.',\n",
       " 'The following are two form letters regarding this.',\n",
       " 'Please send     them around to friends as well as other BBSs       Just sign it and send it, sonny, dont read the fine print.',\n",
       " 'Just   sign it, sonny!',\n",
       " '.',\n",
       " 'Cheers,   Kent            Well you know that youre getting somewhere, when you start getting  responses like this.',\n",
       " 'Kent, let me explain it to you.',\n",
       " 'If you are paying for a phone, and you dont want call waiting, YOU DONT  NEED TO PAY FOR CALl WAITING.',\n",
       " 'This whole Clinton induced abortion debate SHOULD begin to make NARAL  nervous, because it has exposed a real scam.',\n",
       " 'If one is paying for a PRIVATE health insurance plan and DOES NOT WANT   abortion coverage  there is NO reason for that person to be COMPLELLED  to pay for it.',\n",
       " 'Just as one should not be compelled to pay for lipposuction  coverage if ONE doesnt WANT that kind of coverage .',\n",
       " 'There are  basic services  and there are  optional services , Dennis.',\n",
       " 'Call  waiting is an optional service, but having the number     work on ones phone is a basic service.',\n",
       " 'Just because some nutcase doesnt happen to use the     on his phone, since none of the numbers he calls has a     in it, doesnt mean  that he has the right to demand that the phone company  unbundle  the charges for the use of each phone digit  an unbundling that would be horrendously inefficient because of all the billing   bookkeeping overhead.',\n",
       " 'Similarly,  abortion can be seen as a  basic service .',\n",
       " 'Furthermore, public funding of abortion SAVES money, as well as being, in the  views of a substantial portion of the population, probably a clear majority,  an ethical thing to do.',\n",
       " 'If you dont like saving money on your taxes in that  way, why dont you take the taxes you save and invest in private charities  with programs that help reduce the NEED for abortion.',\n",
       " 'If every pro lifer did  the same, it would create a massive economic negative feedback loop which  would all but ELIMINATE the need for public funding of abortion.',\n",
       " 'Then you  would get your wish.',\n",
       " 'And, you know what?',\n",
       " 'No pro choicer I know would stop you carrying out that plan.',\n",
       " 'They might even HELP you with it...            Kevin']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentTokenizer(cleanFile('./data/kaggle/Text_Classification_on_Documents/Politics/178444.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5e91a69-65ea-46fc-9891-dc061497da79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote The most recent reason given the calling federally funded abortions is many private health insurance programs offer coverage abortion. The following are two form letters regarding this. send to friends as well other sign and send it, sonny, dont read the fine print. Just sign it, sonny! . know youre getting somewhere, start getting responses this. let explain to you. are paying a phone, and dont want call waiting, This whole induced abortion debate begin to make nervous, has exposed a real scam. one is paying a health insurance plan and abortion coverage there is reason that person to be COMPLELLED to pay it. Just one should not be compelled to pay lipposuction coverage ONE doesnt kind coverage . There are basic services and there are optional services , Call waiting is an optional service, but having the number work ones phone is a basic service. Just some nutcase doesnt happen to use the phone, none the numbers calls has a it, doesnt mean has the right to demand the phone company unbundle the charges the use each phone digit an unbundling that would be horrendously inefficient all the billing bookkeeping overhead. abortion can be seen a basic service . public funding abortion money, as well being, the views a substantial portion the population, probably a clear majority, an ethical thing to do. dont saving money taxes that way, dont take the taxes save and invest private charities programs that help reduce the NEED abortion. every pro lifer did the same, would create a massive economic negative feedback loop which would all but the need public funding abortion. Then would get wish. know what? No pro choicer know would stop carrying out plan. might even HELP it...\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "sentences = sentTokenizer(cleanFile('./data/kaggle/Text_Classification_on_Documents/Politics/178444.txt'))\n",
    "tagged_word_sentences = nltk.pos_tag_sents([sent.split() for sent in sentences])\n",
    "new_document = str()\n",
    "for sentence in tagged_word_sentences:\n",
    "    # print(sentence)\n",
    "    new_sentence = str()\n",
    "    for word, tag in sentence:\n",
    "        # print(word, tag)\n",
    "        if tag not in ['IN', 'NNP', 'NNPS', 'PRP', 'PRP$', 'WP', 'WP$', 'WRB']:\n",
    "            new_sentence += ' '+word\n",
    "    new_document += ' '+new_sentence.lstrip()\n",
    "    # print(new_sentence.lstrip())\n",
    "    # print(new_sentence)\n",
    "\n",
    "print(new_document.lstrip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece2644e-16ba-4051-a0a3-e09a0f8beca2",
   "metadata": {},
   "source": [
    "### Lemmatize Words, Remove Punctuationa and Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eab5a152-5dec-4a3d-9369-dc4917944447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(word: str) -> str:\n",
    "\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    from nltk.corpus import stopwords    \n",
    "    \n",
    "    new_word = str()                                     # create a string without punctuation\n",
    "    for char in word:                                    # look at each character in the word\n",
    "        if char.isalpha():                               # determine if the character is alphabetic\n",
    "            new_word += char                             # if it is alphabetic, add it to the new word\n",
    "        else:\n",
    "            new_word += ' '\n",
    "\n",
    "    return new_word\n",
    "    \n",
    "def lemmatize(word: str) -> str:\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    wnl = WordNetLemmatizer()\n",
    "    new_word = wnl.lemmatize(word, pos=\"v\")\n",
    "    return new_word\n",
    "    \n",
    "def create_lemmatized_stopwords() -> str:\n",
    "    from nltk.corpus import stopwords\n",
    "\n",
    "    # Create a set of stop words \n",
    "    STOP_WORDS = set(stopwords.words('english'))\n",
    "\n",
    "    stop_words = set()\n",
    "    for word in STOP_WORDS:\n",
    "        new_word = str()                                     # create a string without punctuation\n",
    "        for char in word:                                    # look at each character in the word\n",
    "            if char.isalpha():                               # determine if the character is alphabetic\n",
    "                new_word += char                             # if it is alphabetic, add it to the new word\n",
    "        if new_word != '':\n",
    "            stop_words.add(new_word)\n",
    "\n",
    "    return stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfdad6c2-553c-4d9e-a373-823f01e4fec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = create_lemmatized_stopwords()\n",
    "\"but\" in stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f82c718-3d61-41d8-9d3e-a317e5a701fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cant find source state retract claim go dig one library\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "sentences = sentTokenizer(cleanFile('./data/kaggle/Text_Classification_on_Documents/Politics/124146.txt'))\n",
    "tagged_word_sentences = nltk.pos_tag_sents([sent.split() for sent in sentences])\n",
    "stopwords = create_lemmatized_stopwords()\n",
    "new_document = str()\n",
    "for sentence in tagged_word_sentences[:3]:\n",
    "    # print(sentence)\n",
    "    new_sentence = str()\n",
    "    for word, tag in sentence:\n",
    "        # print(word, tag)\n",
    "        if tag not in ['IN', 'NNP', 'NNPS', 'PRP', 'PRP$', 'WP', 'WP$', 'WRB']:\n",
    "            # new_sentence += ' '+remove_punctuation(word.lower()).strip()\n",
    "            new_word = lemmatize(remove_punctuation(word.lower()).strip())\n",
    "            # print(new_word)\n",
    "            if new_word not in stopwords:\n",
    "                new_sentence += ' '+new_word\n",
    "    if new_sentence != '':\n",
    "        new_document += ' '+new_sentence.strip()\n",
    "    # print(new_sentence.lstrip())\n",
    "    # print(new_sentence)\n",
    "\n",
    "print(new_document.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "558dcda1-298b-4b79-a98d-c20c4252c0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_document(sentTokenizer: list[str]) -> str:\n",
    "    '''Remove Part of Speech Tags, create lowercase, remove punctuation, lemmatize, remove stop words'''\n",
    "\n",
    "    import nltk\n",
    "    sentences = sentTokenizer\n",
    "    tagged_word_sentences = nltk.pos_tag_sents([sent.split() for sent in sentences])\n",
    "    stopwords = create_lemmatized_stopwords()\n",
    "    new_document = str()\n",
    "    for sentence in tagged_word_sentences:\n",
    "        # print(sentence)\n",
    "        new_sentence = str()\n",
    "        for word, tag in sentence:\n",
    "            # print(word, tag)\n",
    "            if tag not in ['IN', 'NNP', 'NNPS', 'PRP', 'PRP$', 'WP', 'WP$', 'WRB']:\n",
    "                # new_sentence += ' '+remove_punctuation(word.lower()).strip()\n",
    "                new_word = lemmatize(remove_punctuation(word.lower()).strip())\n",
    "                # print(new_word)\n",
    "                if new_word not in stopwords:\n",
    "                    new_sentence += ' '+new_word\n",
    "        if new_sentence != '':\n",
    "            new_document += ' '+new_sentence.strip()\n",
    "        # print(new_sentence.lstrip())\n",
    "        # print(new_sentence)\n",
    "    \n",
    "    return new_document.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ed2e6b1-4237-4089-a87f-34442fa40c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cant find source state retract claim go dig one library enough talk retract anything produce talk top head would assume memory source put condition yes serious claim substantiate statement say believe investigate claim investigate state error point provide produce source go dig give one reason go trouble agree simple enough know time waste blow tripe usually post'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 2\n"
     ]
    }
   ],
   "source": [
    "# document '124146.txt'\n",
    "clean_document(sentTokenizer(cleanFile('./data/kaggle/Text_Classification_on_Documents/Politics/124146.txt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b7b7857-0c7d-4211-8965-c0fa37051485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'write recent reason give call federally fund abortions many private health insurance program offer coverage abortion follow two form letter regard send friends sign send sonny read fine print sign sonny  know get somewhere start get responses let explain pay phone want call wait whole induce abortion debate begin make nervous expose real scam one pay health insurance plan abortion coverage reason person complelled pay one compel pay lipposuction coverage one kind coverage basic service optional service call wait optional service number work ones phone basic service nutcase happen use phone none number call mean right demand phone company unbundle charge use phone digit unbundling would horrendously inefficient bill bookkeeping overhead abortion see basic service public fund abortion money view substantial portion population probably clear majority ethical thing save money tax way take tax save invest private charities program help reduce need abortion every pro lifer would create massive economic negative feedback loop would need public fund abortion would get wish know pro choicer know would stop carry plan might even help'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# document '178444.txt'\n",
    "clean_document(sentTokenizer(cleanFile('./data/kaggle/Text_Classification_on_Documents/Politics/178444.txt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652d5348-47a4-4659-a0d3-87192e525f47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
